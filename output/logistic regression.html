<!DOCTYPE html>
 <html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="Logistic Regression¶ General Background¶ Generally speaking, regression methods are supervised learning techniques. They use continous scaled variables (independent variables) to predict the...">
        <meta name="keywords" content="machine learning, python">
        <link rel="icon" href="/extra/favicon.ico">
        <!-- Canonical -->
        <link rel="canonical" href="/logistic regression.html">
        <!-- /Canonical -->

        <title>course: (ML Series) Logistic Regression - Juls-dotcom</title>

        <!-- Stylesheets -->
        <link href="/theme/css/all.min.css" rel="stylesheet">
        <!-- /Stylesheets -->

        <!-- RSS Feeds -->
        <!-- /RSS Feeds -->

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->



    </head>

    <body>

        <!-- Header -->
    <div class="header-container" style="background: linear-gradient(rgba(0, 0, 0, 0.4), rgba(0, 0, 0, 0.4)), url('/images/2020_10_logistic_regression.jpg'); background-position: center; background-size: cover;">

            <!-- Static navbar -->
            <div class="container">
                <div class="header-nav">
                    <div class="header-logo">
                      <!--  <a class="pull-left" href="/"><img class="mr20" src="/logo.jpg" alt="logo">Juls-dotcom</a> -->
                        <a class="pull-left" href="/"><img class="mr20" src="">Juls-dotcom</a>
                    </div>
                    <div class="nav pull-right">
                                <a href="/">Home</a>
                                <a href="/categories.html">Categories</a>
                            <a  href="/pages/CV.html">CV</a>
                            <a  href="/pages/medium.html">@Medium</a>
                            <a  href="/pages/publications.html">Publications</a>
                            <a  href="/pages/talks.html">Talks</a>
                            <a  href="/pages/whois.html">Whois</a>
                    </div>
                </div>
            </div>
            <!-- /Static navbar -->

            <!-- Header -->
    <!-- Header -->
    <div class="container header-wrapper">
        <div class="row">
              <div class="col-lg-12">
                  <div class="header-content">
                      <h1 class="header-title">course: (ML Series) Logistic Regression</h1>
                      <p class="header-date">By <a href="/author/julien-hernandez-lallement.html">Julien Hernandez Lallement</a>, 2020-10-15, in category <a href="/category/course.html">Course</a></p>
                      <div class="header-underline"></div>
                      <div class="clearfix"></div>
                      <p class="pull-right header-tags">
                          <span class="glyphicon glyphicon-tags mr5" aria-hidden="true"></span>
<a href="/tag/machine-learning.html">machine learning</a>, <a href="/tag/python.html">python</a>                      </p>
                  </div>
              </div>
        </div>
    </div>
    <!-- /Header -->
            <!-- /Header -->

        </div>
        <!-- /Header -->


        <!-- Content -->
    <div class="container content">
        <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Logistic-Regression">Logistic Regression<a class="anchor-link" href="#Logistic-Regression">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="General-Background">General Background<a class="anchor-link" href="#General-Background">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Generally speaking, regression methods are supervised learning techniques. They use continous scaled variables (independent variables) to predict the behavior of a dependent variable. They can use different equations that will fit straight lines (linear regression), polynomial functions (detecting interaction effects) or other funcftions to predict the dependent variable.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this post, I will be focusing on logistic regressions, which are typically used as classification algorithms. The logistic regression is however not a classsification algorithm per se, but can be used as such when a probability threshold is set to differentiate between classes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Use-case">Use case<a class="anchor-link" href="#Use-case">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Logisti regressions can be used in different scenarios:</p>
<ul>
<li>Classifying data based on continous scaled features (when the dependent variable is a categorical data, typically binary, i.e., 0 and 1)</li>
<li>Classify whether an email is a spam or not</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Theoretical-Background">Theoretical Background<a class="anchor-link" href="#Theoretical-Background">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's first explain why the most common use of Logistic Regression is classification. Again, to be clear, Logistic Regression is not a classification algorithm per se. It can be used for classification is a threshold is set, above and below which the vector of features will categorize the data point as belonging to one class or the other.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Look at the graph below:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">positive</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">positive</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">negative</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">negative</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

<span class="n">sigmoid</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;linspace(-10,10,100)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">7.5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span> <span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[51]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0, 0.5, &#39;Class&#39;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3gU5fr/8fedkNA7GqqAAvYKgpUWSkC6gICUUEQ9h2MvoP6wHNvRgx0VFaRK6D3SE2I58AUEpQmEJr23hJC2z++PWTSGBFJ2drbcr+uaK7szszMfZpe9d54pjxhjUEopFbxCnA6glFLKWVoIlFIqyGkhUEqpIKeFQCmlgpwWAqWUCnJFnA6QX5UqVTK1atUq0GuTk5MpWbKkZwN5gObKH82Vf76aTXPlT2FyrV279pgx5oocJxpj/GqoX7++Kai4uLgCv9ZOmit/NFf++Wo2zZU/hckFrDG5fK9q05BSSgU5LQRKKRXktBAopVSQ00KglFJBTguBUkoFOdtOHxWRMUA74Igx5qYcpgvwMdAWOAdEG2N+sSuPUspzZq/bz/uLtnLgVApVyxXn+dbX0un2avl+TblCrqMgOQqbKxDZuUcwFoi6xPQ2QF33MBj4wsYsSikPmb1uP8NmbmD/qRQMsP9UCsNmbmD2uv35fs2plPQCr6MgOQqbK1DZtkdgjEkQkVqXmKUjMN59futKESknIlWMMQftyqSUKrz3F20lJT3zb+NS0jN5f9HWXH+N5/aaw6dz/sK91Do63laVN1a8yYwVVUk6UwOTUQRcIZiMENJcIbw6Zj9VelcjIwMyMiA93fqbmcmf4zIzreHV2ac4kVwZjIABY4SzBqYdgAO7wBhrcLlyfgx/Pc5p3IXHF+T3cXaVK5emadPcpxeUGBv7I3AXgvm5NA3NB941xvzofr4MeNEYsyaHeQdj7TUQERFRPyYmpkB5kpKSKFWqVIFeayfNlT+aK/88mW3D/tO5Tru5WtnLvsblgqQzRTl7pihhqeGIqzynTxchKSmMs2eLkJxchAPHXJxPCeP8+SKkpYaSdj6UtNQipKWHkNr0OUzDT+HHF2Hpux75N/mLf/zjN7p1O1Gg1zZr1mytMaZBTtP84hYTxpivgK8AGjRoYJoWsCTGx8dT0NfaSXPlj+bKP09me/nd5ew/lXLR+GrlivOvh5vicsHevbBtG2zfDrt2wbeLDnP2WDiZZ4uRmVwUTM6t0iVKQPnycCI9mczQNELCM5GiaUipTKRIOiF3voyp8R138RQHigzkbOQmJNRlDUVcEOKiUpkwRvS4hbAwCAuDIkWsITT0r78Xhl5f/4/DSeeREPcPYjEghiductGvSytEQARCQsjxsYj7ZZL7uAuPL8jv46zi40/Y8hlzshDsB2pkeV7dPU4p5cOeb30tw2ZuICU9E5MppB0ui+tIeUoUr0nDhrBxI6RkqRNFi0LFyhVIKXaasErHCC2VSmjJ8xQvm87jDTPp0q4BFStaBSA83HrN7HWn/lwHgCGTU0U/4UzIMl667yXebP4mc9YfYNjMHX9rQioeFso7XW6m7e15+7cM733V39ZzYRn1aoUSEVHoTeVxuRWIwnKyEMwFhohIDNAIOK3HB5TybampUP5MNW46WJpFS12c3VcaMkMBWF8Jbr0VHn0Urr8e6tWzhsqVISQkjNnrUnl/0fa/n51zejs33HDxei4ca3h/0Vb2nzpDcsmPOONawZvN3uTlxi9fNE9BzxrKbRnlTm8vzGbyO3aePjoZaApUEpF9wKtAGIAx5ksgFuvU0USs00f725VFKVVwZ87AggUwfTosXAjnzkFoaBnuvBPu7Qp33WUN1apd+hdrp9urXfQlHR+f+xdup9urEXVzRbpP6868bSsY0WoEz9z9zGWXmV/5zRWI7DxrqOdlphvgn3atXylVcC4XLFsG33wDc+ZYewKVK0PfvhAVBU2bQtmcjwt7zLn0c3SK6cSSnUv4vO3nPH7n4/auMIj5xcFipZR3JCXBqFEwcqR1kLdCBaupp3t3uPtu60CpN5xNPUu7ye348Y8f+bbjt0TfFu2dFQcpLQRKKU6ehE8+sYYTJ6BxY3jrLejcGYoV826WU+dP0WZSG1bvX82kLpPocVMP7wYIQloIlApi6enw5Zfw6qtWMejQAYYNs9r8nXDs3DFaTWjFpqObmN59Op2u6+RMkCCjhUCpILVsGfzrX7BlCzRvDh98YJ3145RDSYdoMb4FO07uYE6POUTVudQdapQn6d1HlQoyyckwZAi0aAFpaTB7Nixd6mwR2Ht6L42/bczuU7uJ7RWrRcDLdI9AqSCyahX07g2JifD009ZxgOLFnc208+ROIsdHciLlBIv7LOaeGvc4GygI6R6BUkFi9Gi4/37ruMDy5VZTkNNF4I9zf9D428acST3Dsr7LtAg4RPcIlApwGRnwySd1mDULWraEKVOs2zk4beORjTy1/inCwsOI6xfHLRG3OB0paOkegVIBLDkZHngAZs2qztNPQ2ysbxSBXw7+QpOxTQiVUFZEr9Ai4DAtBEoFqLNnoW1b60Dwc89t5YMPrLtvOm3lvpU0H9ec0uGl+ei2j7iu0nVORwp6WgiUCkCnT0Pr1vDTTzBpEjzwgG/czzF+dzwtxrfgipJXkNA/gWrFC3efIOUZWgiUCjDJydCqFaxZA1OnQg8fuTB3UeIi2kxqQ81yNUmITuCqslc5HUm5aSFQKoBkZFhf/GvWwLRp0KWL04ksc36fQ4eYDlxb8Vri+8VTpXQVpyOpLLQQKBUgjIEnn4T58+Gzz6BjR6cTWaZtmkbXaV25rfJtxPWL44qSVzgdSWWjhUCpADFiBHz+OTz/PDzuI3dsHv/reHrM6MFd1e9iSZ8llC/uA6csqYtoIVAqACxdCi+8AN26wbs+0p/7qDWj6De7H81qNWPhwwspU7SM05FULrQQKOXnDh2ybhtx/fXw7bfe6zPgUj5a+RGPLXiMB+o+wPxe8ykZXtLpSOoSfOCsYqVUQWVmWkXgzBnrbqIlfeD79p0f3uGl5S/R5fouTH5wMuGh4U5HUpehhUApP/b22391KXnjjc5mMcYwPG44b/7wJr1u7sW4TuMoEqJfMf5A3yWl/NSaNfDaa9CrFwwY4GwWYwzPLX6OD1Z+wMDbBzKq3ShCQ0KdDaXyTAuBUn4oPR0GDYKICOtMIRHnsriMiyGxQ/hizRcMuXMIH7f5mBDxgQMVKs+0ECjlh0aMgF9/hVmzoGxZ53JkujIZNG8QY9eP5YV7XuDdFu8iTlYlVSBaCJTyM9u3W01CDz4InRzs0jc9M50+s/owZdMUXmvyGsObDNci4Ke0ECjlR4yBwYOhWDH49FPncqRmpNJjRg9m/z6b/7T4Dy/c+4JzYVShaSFQyo9MmQLx8TBqFFRx6HY9KekpdJnahYWJC/kk6hP+1ehfzgRRHqOFQCk/cf48DB0Kt90GAwc6kyEpLYkOkzsQvzuer9t/zaA7BjkTRHmUFgKl/MSnn8KePVbfw6EOnJl5+vxp2n7XllX7VjG+83h639Lb+yGULbQQKOUHjh2Dt96yup2MjPT++k+knKD1xNasP7SeKV2n8OAND3o/hLKNFgKl/MAbb0BSErz3nvfXfST5CC3Gt2Db8W3MemgW7eq1834IZSstBEr5uMRE+OILeOQRuOEG7657/5n9tJjQgj9O/8H8XvNpcXUL7wZQXqGFQCkf99ZbVqfzr77q3fXuObWH5uObczT5KAsfXsj9Ne/3bgDlNbZeBy4iUSKyVUQSRWRoDtOvEpE4EVknIr+JSFs78yjlb3btggkTrGsHKlf23noTTyRy/7f3cyLlBEv7LtUiEOBsKwQiEgqMBNoANwA9RST7ju0rwFRjzO1AD+Bzu/Io5Y/efdc6Q+gFL16vtfnoZhp/25iUjBTi+sXRsFpD761cOcLOPYKGQKIxZqcxJg2IAbL3omqAC90WlQUO2JhHKb+yd6/V0czAgVCtmnfW+euhX2kytgkGQ3y/eG6rfJt3VqwcJcYYexYs0hWIMsYMcj/vAzQyxgzJMk8VYDFQHigJtDDGrM1hWYOBwQARERH1Y2JiCpQpKSmJUqVKFei1dtJc+RMsuT7+uC7z5lVh4sRVVK6cWqhl5SXbljNbeGHDCxQPLc4Ht3xA9RLVC7VOT+VyQiDmatas2VpjTIMcJxpjbBmArsA3WZ73AT7LNs8zwLPux3cDm4GQSy23fv36pqDi4uIK/Fo7aa78CYZcBw4YU7SoMQMHemZ5l8uWsDvBlH67tKn9UW2z6+Quz6w0D4LhvfSkwuQC1phcvlftbBraD9TI8ry6e1xWA4GpAMaY/wHFgEo2ZlLKL3z2GaSlWbeUsNvSnUuJmhRF1dJV+aH/D9QqV8v+lSqfYmchWA3UFZHaIhKOdTB4brZ5/gAiAUTkeqxCcNTGTEr5vJQU66ZyHTtCnTr2rmvBtgW0+64d15S/hhXRK6hWxksHI5RPsa0QGGMygCHAImAL1tlBm0TkDRHp4J7tWeAREfkVmAxEu3dhlApakybB8ePw5JP2rmfG5hl0ntKZm668ibh+cUSUirB3hcpn2XpBmTEmFojNNm54lsebgXvtzKCUPzEGPv4Ybr0VmjSxbz3fbfiOvrP60qh6I2J7xVK2mIPdnCnH6ZXFSvmQ5cth40YYM8a+fohH/zKaR+Y9QpNaTZjXcx6lwn3v7BjlXdrDtFI+5OOP4YoroGdPe5Y/8v9GMmjeIFrXaU1sr1gtAgrQQqCUz0hMhPnz4bHHrK4oPe39n95nyPdD6HhtR2Y/NJviYcU9vxLll7RpSCkfMWqUdTuJxx/37HKNMYzbPY6xe8by0I0PMaHzBMJCwzy7EuXXdI9AKR+QlgbjxkH79p7ti9gYw7Blwxi7Zyz9bu3HpC6TtAioi+gegVI+YO5cOHrU6nPAU1zGxVMLn+LT//uUDlU7MKbjGEJEf/upi2khUMoHfP011KgBrVp5ZnmZrkwem/8Y36z7hqfvepr24e21CKhc6SdDKYft3g1LlsCAAZ7plD7DlUH0nGi+WfcNr9z/CiNajUDsOhdVBQTdI1DKYaNHW38HDCj8stIy0+g1oxcztszgreZv8dL9LxV+oSrgaSFQykEZGVafA1FRcNVVhVvW+YzzdJvWjfnb5vNh6w956q6nPBNSBTwtBEo5aOFC2L8fPv20cMtJTkum05ROLN25lC8e+ILHGjzmmYAqKGghUMpB48dbVxK3a1fwZZxJPUO779rx096fGNtxLP1u6+e5gCooaCFQyiGnTlmnjQ4eDGEFPLX/ZMpJoiZF8cvBX/iuy3c8dNNDng2pgoIWAqUcMmMGpKZCnz4Fe/3R5KO0mtiKzUc3M73bdDpel71LcKXyRguBUg6ZMAHq1YMGOfcie0kHzx6kxYQW7Dy5k7k95tK6TmvPB1RBQ68jUMoBf/wBK1ZA7975v9303tN7aTK2CXtO7WHhwwu1CKhC0z0CpRwwaZL19+GH8/e6nSd30nxcc06dP8WSPku4u8bdng+ngo4WAqW8zBirWejee+Hqq/P+uq3HthI5PpKUjBSW91vOHVXusC+kCiraNKSUl61bB1u25O8g8YbDG2g8tjHprnTi+8VrEVAepYVAKS+bNMk6XbRbt7zNv/bAWpqOa0pYSBgJ0QncHHGzvQFV0NFCoJQXuVwwbRq0bg0VKlx+/p/3/kzz8c0pHV6ahP4JXFvpWvtDqqCjhUApL1q5Evbuhe7dLz9v3K44Wk1oxZUlr+SH/j9wdfl8HFBQKh+0ECjlRVOnQtGi0PEy134tTFxI2+/aUrNcTRKiE6hRtoZ3AqqgpIVAKS+50CwUFQVlyuQ+35zf59AxpiPXVbqOFdErqFLag31XKpUDLQRKeclPP8GBA/DQJW4HNGXjFLpO68rtlW9ned/lVCpRyXsBVdDSQqCUl0ydCsWK5X6n0XHrx9FrZi/uqXEPS/osoXzx8t4NqIKWFgKlvCAzE6ZPh7ZtoXTpi6d/ueZLoudE07x2c75/+HtKF81hJqVsooVAKS/44Qc4dCjnZqEP//chjy94nPb12jOv5zxKhJXwfkAV1LQQKOUFU6dC8eLwwAN/H/9Wwls8s/gZut7Qlendp1OsSDFnAqqgpoVAKZu5XDBrltUsVLKkNc4YwyvLX+GVuFfoc0sfJj84mfDQcGeDqqBlayEQkSgR2SoiiSIyNJd5uovIZhHZJCLf2ZlHKSesXGk1C3XpYj03xvDs4md564e3GHT7IMZ2GkuREL3/o3KObZ8+EQkFRgItgX3AahGZa4zZnGWeusAw4F5jzEkRudKuPEo5ZeZM695CDzwALuPinwv+yZdrv+SJhk/wUdRHSH47JFDKw+zcI2gIJBpjdhpj0oAYIPv1lI8AI40xJwGMMUdszKOU1xljFYIWLaBU6UwGzBnAl2u/5MV7X9QioHyGGGPsWbBIVyDKGDPI/bwP0MgYMyTLPLOBbcC9QCjwmjFmYQ7LGgwMBoiIiKgfExNToExJSUmUKlWqQK+1k+bKH3/KlZhYikceacDTz21gfe0niTsaR3TNaPrW7OvVIuBP28wXBGKuZs2arTXG5NwxqjHGlgHoCnyT5Xkf4LNs88wHZgFhQG1gL1DuUsutX7++Kai4uLgCv9ZOmit//CnXK68YI2HnTdTYDobXMO/9+J73gxn/2ma+IBBzAWtMLt+rdjYN7Qey3imruntcVvuAucaYdGPMLqy9g7o2ZlLKq6bPOUe5xzuycPdcPmvzGc/f+7zTkZS6iJ2FYDVQV0Rqi0g40AOYm22e2UBTABGpBNQDdtqYSSmvWbvhLL/f8QCnKixmdIfR/LPhP52OpFSObCsExpgMYAiwCNgCTDXGbBKRN0Skg3u2RcBxEdkMxAHPG2OO25VJKW85df4UXWa1hpo/8EnTSQy4fYDTkZTKla0nLxtjYoHYbOOGZ3lsgGfcg1IB4fi547Sa2Iq9mRuos24qQ17v4nQkpS5JryxWyoMOJx2m2bhmbDqyCTN5NgPu1iKgfJ8WAqU85GjqUZqMbcKOkzt4tPQC2N6WTp2cTqXU5WkhUMoDdp/azZPrn+TA2QMs6r2I32MjqVcPrrvO6WRKXZ4WAqUKafvx7dz/7f2czTjL0r5LubnsfcTFWf0S64XDyh/kqRCIyJMiUkYso0XkFxFpZXc4pXzdpiObaDy2MeczzvPhrR/SsFpDvv8e0tPRZiHlN/K6RzDAGHMGaAWUx7pK+F3bUinlB9YdXEfTcU0RhBXRK6hTqg4As2dDRAQ0auRwQKXyKK+F4MIObltggjFmU5ZxSgWdVftW0Xx8c0qElSChfwI3XHEDAKmpEBsL7dtDaKjDIZXKo7wWgrUishirECwSkdKAy75YSvmuhD0JtJjQggrFK5AQnUCdCnX+nBYfD2fParOQ8i95vaBsIHAbsNMYc05EKgD97YullG9aunMpHSZ3oGa5mizts5RqZar9bfrs2VYvZJGRDgVUqgDyukdwN7DVGHNKRHoDrwCn7YullO+Zv20+7b5rR50KdVgRveKiIuBywZw5EBUFxbTrYeVH8loIvgDOicitwLPADmC8bamU8jHTN0+n85TO3BxxM/HR8VxZ8uLO9LZuLc3Bg9Zpo0r5k7wWggz3fYE6YvUpMBIobV8spXzHxN8m8tD0h2hYrSFL+yylQvEKOc7388+VCA21uqRUyp/ktRCcFZFhQG9ggYiEYHUmo1RA++aXb+g7qy9NazVlUe9FlC1WNtd5f/qpIvffDxVyrhNK+ay8FoKHgFRgoDHmEFYnM+/blkopH/Dpqk95ZN4jRNWJYn7P+ZQKz72LwJ07YdeuUtospPxSns4acn/5f5Dl+R/oMQIVwN776T1eXPoina/rzOQHJ1O0SNFLzj9njvVXC4HyR3m9xcRdIrJaRJJEJE1EMkVEzxpSAccYw2vxr/Hi0hfpeVNPpnSdctkiAFYhuPrqJGrX9kJIpTwsr01DnwE9ge1AcWAQ8LldoZRygjGGoUuH8vqK1+l/W38mdJ5AWOjlD4UdPw4//AD33nvMCymV8rw8333UGJMIhBpjMo0x3wJR9sVSyrtcxsUT3z/Bez+/x+MNHuebDt8QGpK3e0QsWGBdQ3DvvdrLqvJPeb2y+Jy7A/r1IvIecBC9hbUKEJmuTB6d/yij143mmbue4b+t/ovk4/7Rc+ZAtWpQr95ZG1MqZZ+8fpn3AUKxOqNPBmoAD9oVSilvyXBl0Hd2X0avG80r97+S7yKQkgKLFkGHDtr3gPJfeT1raI/7YQrwun1xlPKetMw0es7oycwtM3m7+dsMu39YvpexbBkkJ+tN5pR/u2QhEJENgMltujHmFo8nUsoLzmec58GpDxK7PZaPWn/Ek3c9WaDlzJkDZcpA06bw88+ezaiUt1xuj6ALEAHszTa+BnDIlkRK2Sw5LZmOMR1Zvms5o9qNYnD9wQVaTmYmzJ0LbdtCeLiHQyrlRZc7RvAhcNoYsyfrgHXn0Q/tj6eUZ51JPUPUpCjidscxttPYAhcBgJUr4cgRbRZS/u9yewQRxpgN2UcaYzaISC1bEillkxMpJ4iaGMW6Q+uIeTCGbjd2K9TyZs+GsDBo08ZDAZVyyOUKQblLTCvuySBK2elo8lFaTmjJlmNbmNF9Bh2u7VCo5RljFYLmza1jBEr5s8s1Da0RkUeyjxSRQcBaeyIp5VkHzx6kydgmbDu+jXk95xW6CABs2QKJidospALD5fYIngJmicjD/PXF3wAIBzrbGUwpT/jj9B9Ejo/kUNIhvn/4e5rUauKR5c6ebf3tUPiaopTjLlkIjDGHgXtEpBlwk3v0AmPMctuTKVVIO07sIHJ8JKfOn2JJnyXcVf0ujy179mxo2BCqVvXYIpVyTF4vKIsD4mzOopTH/H7sdyLHR5Kakcryfsu5o8odHlv23r2wejW8/bbHFqmUo/J6ryGl/MZvh3+jxfgWhEgI8dHx3HTlTZd/UT5caBZ6UG+yogKErTeOE5EoEdkqIokiMvQS8z0oIkZEGtiZRwW+NQfW0GxcM8JDw0non+DxIgAwcybceCPUq+fxRSvlCNsKgYiEAiOBNsANQE8RuSGH+UoDTwKr7MqigsPPe38mcnwkZYqW4Yf+P1Cvoue/qY8ehYQE6NLF44tWyjF27hE0BBKNMTuNMWlADJBTR37/Bv4DnLcxiwpwy3ctp+WElkSUjCAhOoHa5e3pKmzOHKvvAW0WUoFEjMn1nnKFW7BIVyDKGDPI/bwP0MgYMyTLPHcALxtjHhSReOA5Y8yaHJY1GBgMEBERUT8mJqZAmZKSkihVKvcOyJ2iufIne65Vx1cxfPNwqharyohbR1AhvIJt6x469Gb27i3BxImrLrrttK9uL/DdbJorfwqTq1mzZmuNMTk3vxtjbBmArsA3WZ73AT7L8jwEiAdquZ/HAw0ut9z69eubgoqLiyvwa+2kufIna66Zm2easDfCzO1f3m6OJh+1db2nThkTFmbMc89dPpev8dVsmit/CpMLWGNy+V61s2loP9ZdSi+o7h53QWmsaxPiRWQ3cBcwVw8Yq7yK2RhDt2ndqF+1Psv7LadSiUq2rm/BAkhP1+MDKvDYWQhWA3VFpLa7m8sewNwLE40xp40xlYwxtYwxtYCVQAeTQ9OQUtl9u+5bes3oxX1X3cfi3ospV+xSt8XyjJkzrQvIGjWyfVVKeZVthcAYk4HVteUiYAsw1RizSUTeEBG9MF8V2JwDcxgwdwAtr2lJ7MOxlC5a2vZ1JifD999b9xYK0d66VYCx9YIyY0wsEJtt3PBc5m1qZxYVGD743wd8tP0j2tdrz9RuUylWpJhX1rtgAZw7B927e2V1SnmV/rZRfuOthLd4dvGzNLmiCTO6z/BaEQCYOhUqV4b77vPaKpXyGr3FhPJ5xhheWf4Kb//4Nn1u6UO/cv0ICw3z2vqTkqw9gkGDIDTUa6tVymt0j0D5NGMMzyx6hrd/fJvBdwxmbKexhIp3v43nzYPz5+Ghh7y6WqW8RvcIlM9yGRf/WPAPRq0dxRMNn+CjqI+Q7FdxecHUqdbZQvfc4/VVK+UVukegfFKGK4P+c/ozau0oht471LEicOaMdbZQt256tpAKXLpHoHxOemY6vWf1ZuqmqbzR9A1eafyKI0UAYO5cSE3VZiEV2LQQKJ9yPuM83ad1Z962ebzf8n2eu+c5R/NMnQo1auhFZCqw6c6u8hnn0s/RMaYj87bNY2TbkY4XgZMnYdEibRZSgU/3CJRPOJt6lvaT25OwJ4ExHcbQ//b+Tkdi2jRIS4NevZxOopS9tBAox506f4o2k9qwev9qJnWZRM+bezodCYCJE+H66+EOz3V3rJRP0h1e5ahj544ROT6StQfWMq3bNJ8pArt3ww8/QO/eXNTvgFKBRvcIlGMOJR2i5YSWJJ5IZHaP2bSt29bpSH+aNMn6q81CKhhoIVCO2HdmH5HjI9l/Zj8Lei2gee3mTkf6kzEwYQI0bgy1ajmdRin7adOQ8rpdJ3fR+NvGHEo6xKLei3yqCACsXQtbt1rNQkoFA90jUF617fg2IsdHkpyWzLK+y2hQ1fc6pJswAcLDrdNGlQoGWgiU12w8spEW41vgMi7io+O5JeIWpyNdJCMDJk+G9u2hnP2dninlE7RpSHnFuoPraDq2KSESworoFT5ZBMC63fTRo9Cnj9NJlPIeLQTKdiv3raTZuGaUDC9JQv8Err/ieqcj5errr6FKFXjgAaeTKOU9WgiUrVbsXkHLCS2pVKISCdEJ1KlQx+lIudq3z7rTaHQ0FNFGUxVEtBAo2yzesZg2k9pQvUx1EvonULNcTacjXdK334LLBQMHOp1EKe/SQqBsMW/rPNpPbk+9ivVYEb2CqqWrOh3pklwuGD0aIiPhmmucTqOUd2khUB43bdM0ukztwq0Rt7K833KuLHml05Eua8kS2LMHHnnE6SRKeZ8WAuVRE36dQI8ZPbir+l0s7buUCsUrOB0pT77+GipWhE6dnE6ilPdpIVAe89Xar+g3ux9NazVl4cMLKVO0jNOR8uTwYZgzB/r1g6JFnU6jlPdpIVAe8emqT3l0/qO0qduG+T3nU1XSBKcAABLuSURBVDK8pNOR8mzUKOtCssGDnU6ilDO0EKhCe/fHd3li4RN0vq4zsx6aRfGw4k5HyrPUVPjiC2jTBq691uk0SjlDC4EqMGMMr8a9yrBlw+h1cy+mdptKeGi407HyZepUOHQInnrK6SRKOUcvm1EFYozhhSUv8N///ZcBtw3gq/ZfERoS6nSsfDEGPv7Y6oWsZUun0yjlHC0EKt9cxsUT3z/ByNUj+eed/+STNp8QIv63c/nzz9Ytp7/8UnshU8FNC4HKl0xXJoPnDWbM+jE8d/dzvNfyPcRPv0U/+gjKl9cbzCll6884EYkSka0ikigiQ3OY/oyIbBaR30RkmYj49j0Iglx6Zjp9Z/dlzPoxDG883K+LwJ49MGuWdQFZiRJOp1HKWbYVAhEJBUYCbYAbgJ4ickO22dYBDYwxtwDTgffsyqMKJy0zjYemP8R3G77jnch3eL3Z635bBADeew9CQmDIEKeTKOU8O/cIGgKJxpidxpg0IAbomHUGY0ycMeac++lKoLqNeVQBpaSn0HlKZ2b9PouPoz5m6H0X7dz5lQMHrPsKRUdDjRpOp1HKeWKMsWfBIl2BKGPMIPfzPkAjY0yOv8FE5DPgkDHmzRymDQYGA0RERNSPiYkpUKakpCRKlSpVoNfayZdzhRYP5eWNL7P+1Hqervs07au2dzpWobfXyJHXMHNmdSZOXEWVKud9JpedfDWb5sqfwuRq1qzZWmNMzn3DGmNsGYCuwDdZnvcBPstl3t5YewRFL7fc+vXrm4KKi4sr8Gvt5Ku55i2ZZ+4dfa8JeT3EjF8/3uk4fyrM9jp0yJhixYyJjvZcngt89X00xnezaa78KUwuYI3J5XvVzrOG9gNZd7yru8f9jYi0AF4GmhhjUm3Mo/LhRMoJnvvtOXYk7yDmwRi63RgYPbmPGAFpafDSS04nUcp32HmMYDVQV0Rqi0g40AOYm3UGEbkdGAV0MMYcsTGLyocjyUdoNq4ZO5N2MuuhWQFTBI4dg88/hx49oG5dp9Mo5TtsKwTGmAxgCLAI2AJMNcZsEpE3RKSDe7b3gVLANBFZLyJzc1mc8pIDZw/QZGwTth/fzts3vU27eu2cjuQxb78NKSnw8stOJ1HKt9h6QZkxJhaIzTZueJbHLexcv8qfP07/QfNxzTmcfJiFvRfi2uVyOpLH7NgBn30GAwbADdlPYlYqyPnffQGULXac2MH9397P8ZTjLO2zlMY1GzsdyaOGDoXwcHjjDaeTKOV7tBAothzdQuOxjUlOS2Z53+U0qt7I6Uge9dNPMH06vPACVKnidBqlfI/eayjI/XroV1pOaEmIhLAiegU3Xnmj05E8yhh49lmoWtX6q5S6mBaCILZ6/2paT2xNyfCSLOu7jHoV6zkdyeMmT4ZVq2DMGCjpP52mKeVV2jQUpH7840cix0dStlhZEqITArIIHD9udTjToAH07et0GqV8l+4RBKHlu5bTfnJ7qpepzrK+y6heJjBv8fTss3DyJCxZAqH+1WeOUl6lewRBJnZ7LG0nteXq8leTEJ0QsEVgyRIYN846QHzrrU6nUcq3aSEIIrO2zKJTTCduvPJG4vrFEVEqwulItkhOhkcfhXr14P/9P6fTKOX7tGkoSHy34Tv6zurLndXu5PuHv6dcsXJOR7LNiy/Crl0QHw/FijmdRinfp3sEQWDMujH0ntmb+666j8W9Fwd0EZgxA0aOhKefhiZNnE6jlH/QQhDgRv7fSAbOHUira1oR+3AspYuWdjqSbXbuhIEDoWFDePddp9Mo5T+0EASw//78X4Z8P4QO13ZgTo85lAgL3M5509Ksu4oCxMRYt5NQSuWNHiMIQMYY3kx4k+Hxw+l+Y3cmdp5IWGiY07FsY4x1vcDq1VbTUO3aTidSyr9oIQgwxhheXv4y7/z4Dn1v7cuYDmMIDQnsk+hHjIAvvrBOFe3Sxek0SvkfLQQBxBjD04ue5uNVH/No/Uf5/IHPCZHAbv2bNg2efx66d4d33nE6jVL+SQtBgHAZF4/Pf5yvfvmKJxs9yYetP0REnI5lqx9/hD594N57rYvHQgK75illGy0EASDDlcGAOQOY8NsEht03jLeavxXwReCHH6BtW6hZE+bM0esFlCoM/Q3l59Iy0+g1oxcTfpvAm83e5O3ItwO+CKxdW46oKKheHeLioGJFpxMp5d90j8CPnc84T/dp3Zm3bR4jWo3gmbufcTqS7WJj4aWXbqZePVi6FCIC8y4ZSnmV7hH4qXPp5+gwuQPzts3j87afB3wRMAY+/BDat4eaNc8RF6dFQClP0T0CP3Q29SwPfPcAP+39iTEdxtD/9v5OR7JVaio89hiMHWudHjpo0HoqVbrf6VhKBQzdI/AzJ1NO0nJCS37e+zOTukwK+CKwZQvcd59VBF57zTpdtHjxTKdjKRVQdI/AjxxNPkqria3YfHQz07tPp9N1nZyOZBuXCz75BIYNs7qYnDULOgXuP1cpR2kh8BOHkg7RYnwLdpzcwZwec4iqE+V0JNusWwdPPmmdItquHXz9NVSu7HQqpQKXNg35gb2n99L428bsPrWb2F6xAVsEDh2CQYOgfn3YvBlGj4a5c7UIKGU33SPwcbtO7qL5+OacSDnB4j6LuafGPU5H8rh9+6z7BX31lXUX0aeftnoWKxe43SYo5VO0EPiwbce30Xxcc1IyUljWdxkNqjZwOpLHGGPdLfTLL2HiROuYwMMPwyuvQN26TqdTKrhoIfBRG49spMX4FhgMcf3iuCXiFqcjecSBAzB9utXs89tvUKIEPPKIdeO4WrWcTqdUcNJC4IN+OfgLLSe0pFiRYizru4zrKl3ndKQCM8Zq71+0CGbOhJ9/tsbVr2/tDfTsCWXKOJ1SqeCmhcDHrNy3kqiJUZQrVo5lfZdxTYVrnI6UL5mZsHEjrFwJP/0Ey5ZZewEAt94Kr78ODz4IN9zgbE6l1F+0EPiQ+N3xtPuuHVVKV2FZ32VcVfYqpyPlyhjrLJ+tW+H33+HXX62mnl9/heRka54rroDmzaFFC2vQph+lfJOthUBEooCPgVDgG2PMu9mmFwXGA/WB48BDxpjddmYqkN+mwrI34PQ+KFsdIofDLd09t9zKg1j8fjQdzx/g6op1WdpnKVVKV7n8em3KlfHLNI7N+4ydxQaRMWUQB6o/wsEijdi3D/bsgd27YdcuSEr66zVly8Itt0D//tCoEdx9N1x9NQT4jVCVCgi2FQIRCQVGAi2BfcBqEZlrjNmcZbaBwEljTB0R6QH8B3jIrkwF8ttUmPcEpKdYz0/vtZ5D4b50syz3p1IbeSN5D9dLEZbc+TRXuIuAmfsErrRUMk0RMo4dI3P6MDLOhJFxbWcyfptL+sL/kJ5ahHRXHTKOFCF1+zek3V2R1BqRpKbC+fPWkJJiDefOWb/WLwxnz8KZM9Zw6hScOAEnj6dx+mw3oJs7aJ8/I5cta/2qr10bmjWDevWs4dproUYN/dJXyl/ZuUfQEEg0xuwEEJEYoCOQtRB0BF5zP54OfCYiYowxng4zejS8/npDSpSwnmddwyUfn7oLXD9jkCzjBT4IxZT5a35jch6yTnO5sjw+1xpjfiet3lzOdRxIyKEGbJ08mxpvViITcGU+iMvkUGj+feFBB/eQzReX3xZFi1q3bShT5q+hShWr3b787mlUDN3DFSWPc6ROc5qdHkm1MgepUrUIJYeuvvzClVJ+x85CUA3Ym+X5PqBRbvMYYzJE5DRQETiWdSYRGQwMBoiIiCA+Pj7fYQ4frkitWhUoUuSv9gyRnOtN1l+2cj45x/FgoPghRP4af2F5F8ZlXb4IhIT8NT0k5SiI4VTJUDafvY97Dr1GeJODhIQcQEpfSci5Q4SEGEJCDKEhLkJDDKGhLut5+SqEJu8lNMRFkVAXRYq4KBKaSViRTOvxlbUJD3cRHu4iLMxFsWIuihZ1ER6eSfHiLkJDL1FnDx4FSgAluKpoMia1Ffuw3jwKsN3tkJSUVKDPgN18NRf4bjbNlT925fKLg8XGmK+ArwAaNGhgmjZtmu9lNG0K99wTT75f+2Gk1RyUXdka8PTGfOf4a7mt/1xu/LWv07Rsh78v98MHLr3eD7vYlGvI33NtffWv5fYsxHI9KD6+AO+jF/hqLvDdbJorf+zKZee9hvYDNbI8r+4el+M8IlIEKIt10Nh3RA6HsOJ/HxdW3Bpv53ILO92uXEqpgGNnIVgN1BWR2iISDvQA5mabZy7Qz/24K7DcjuMDhXJLd2j/ifWLGLH+tv+k8Gfn/G25XLzcy63XqVxKqYBjW9OQu81/CLAI6/TRMcaYTSLyBrDGGDMXGA1MEJFE4ARWsfA9t3S354vwwnLj43Nudrncep3KpZQKKLYeIzDGxAKx2cYNz/L4PH+dp6iUUsoB2h+BUkoFOS0ESikV5LQQKKVUkNNCoJRSQU587WzNyxGRo8CeAr68EtmuWvYRmit/NFf++Wo2zZU/hclV0xhzRU4T/K4QFIaIrDHG+Fx/j5orfzRX/vlqNs2VP3bl0qYhpZQKcloIlFIqyAVbIfjK6QC50Fz5o7nyz1ezaa78sSVXUB0jUEopdbFg2yNQSimVjRYCpZQKcgFXCESkm4hsEhGXiDTINm2YiCSKyFYRaZ3L62uLyCr3fFPct9D2dMYpIrLePewWkfW5zLdbRDa451vj6Rw5rO81EdmfJVvbXOaLcm/DRBEZ6oVc74vI7yLym4jMEpFyucznle11uX+/iBR1v8eJ7s9SLbuyZFlnDRGJE5HN7s//kznM01RETmd5f73SycTl3hexfOLeXr+JyB1eyHRtlu2wXkTOiMhT2ebx2vYSkTEickRENmYZV0FElojIdvff8rm8tp97nu0i0i+neS7LGBNQA3A9cC0QDzTIMv4G4FegKFAb2AGE5vD6qUAP9+MvgcdtzjsCGJ7LtN1AJS9uu9eA5y4zT6h7210NhLu36Q0252oFFHE//g/wH6e2V17+/cA/gC/dj3sAU7zw3lUB7nA/Lg1syyFXU2C+tz5PeX1fgLbA94AAdwGrvJwvFDiEdcGVI9sLaAzcAWzMMu49YKj78dCcPvdABWCn+2959+Py+V1/wO0RGGO2GGO25jCpIxBjjEk1xuwCEoGGWWcQEQGaA9Pdo8YBnezK6l5fd2CyXeuwQUMg0Riz0xiTBsRgbVvbGGMWG2My3E9XYvV255S8/Ps7Yn12wPosRbrfa9sYYw4aY35xPz4LbMHqE9wfdATGG8tKoJyIVPHi+iOBHcaYgt6xoNCMMQlYfbJklfVzlNt3UWtgiTHmhDHmJLAEiMrv+gOuEFxCNSBrJ7/7uPg/SkXgVJYvnZzm8aT7gcPGmO25TDfAYhFZKyKDbcyR1RD37vmYXHZF87Id7TQA69djTryxvfLy7/9zHvdn6TTWZ8sr3E1RtwOrcph8t4j8KiLfi8iNXop0uffF6c9UD3L/MebE9rogwhhz0P34EBCRwzwe2XZ+0Xl9diKyFKicw6SXjTFzvJ0nJ3nM2JNL7w3cZ4zZLyJXAktE5Hf3LwdbcgFfAP/G+o/7b6xmqwGFWZ8ncl3YXiLyMpABTMplMR7fXv5GREoBM4CnjDFnsk3+Bav5I8l9/Gc2UNcLsXz2fXEfA+wADMthslPb6yLGGCMitp3r75eFwBjTogAv2w/UyPK8untcVsexdkuLuH/J5TSPRzKKSBGgC1D/EsvY7/57RERmYTVLFOo/UF63nYh8DczPYVJetqPHc4lINNAOiDTuxtEcluHx7ZWDvPz7L8yzz/0+l8X6bNlKRMKwisAkY8zM7NOzFgZjTKyIfC4ilYwxtt5cLQ/viy2fqTxqA/xijDmcfYJT2yuLwyJSxRhz0N1UdiSHefZjHcu4oDrW8dF8CaamoblAD/cZHbWxKvv/ZZ3B/QUTB3R1j+oH2LWH0QL43RizL6eJIlJSREpfeIx1wNTWDoSztct2zmV9q4G6Yp1dFY61Wz3X5lxRwAtAB2PMuVzm8db2ysu/fy7WZwesz9Ly3IqXp7iPQYwGthhjPshlnsoXjlWISEOs//+2Fqg8vi9zgb7us4fuAk5naRKxW6575U5sr2yyfo5y+y5aBLQSkfLuptxW7nH5440j4t4csL7A9gGpwGFgUZZpL2Od8bEVaJNlfCxQ1f34aqwCkQhMA4ralHMs8Fi2cVWB2Cw5fnUPm7CaSOzedhOADcBv7g9hley53M/bYp2VssNLuRKx2kHXu4cvs+fy5vbK6d8PvIFVqACKuT87ie7P0tVe2Eb3YTXp/ZZlO7UFHrvwOQOGuLfNr1gH3e/xQq4c35dsuQQY6d6eG8hytp/N2UpifbGXzTLOke2FVYwOAunu76+BWMeVlgHbgaVABfe8DYBvsrx2gPuzlgj0L8j69RYTSikV5IKpaUgppVQOtBAopVSQ00KglFJBTguBUkoFOS0ESikV5LQQKKVUkNNCoJRSQe7/A8ig/UhQcSUxAAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, the y axis shows the classified nature of the data points (spam or not spam), and the x axis shows a feature of these data points (say, the number of spelling mistakes in the mail's object).</p>
<p>As you can imagine, a linear fit (green line; <strong>not real linear fit</strong>) would be quite poor in this case. If new data comes in, with <code>y=1</code>, but with a high value of x, your linear fit will show a tremendous increase in residuals, and fit the data poorly.</p>
<p>Moreover, if the y axis does not reflect classes but probabilities of belonging to a class, you will have issues because your linear fit might predict values &gt;1 or &lt;0, which would be nonsense.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One way to circumvent this problem is to use a <code>sigmoidal function</code>, such as the logistic function:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
h_0(x) = \frac{1}{1 + e^{-\theta_o - \theta_1x}}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function is shown in the figure above as blue line. Using it, a new comer data point would be classified as 1 or 0 based on the probability threshold for $h_0$.</p>
<p>Let's have a closer look at it:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">e</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_values</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[55]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.lines.Line2D at 0x7f7a34539210&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see why this is a great function for a probability measure. The y-value represents the probability and only ranges between 0 and 1. Also, for an x value of zero you get a .5 probability and as you get more positive x values you get a higher probability and more negative x values a lower probability.</p>
<p>The aforementionned threshold should be decided based on business knowledge and common sense. A threshold = 0.5 would be quite flexible, allowing some "smart" spams (if that exists) to land in the mailbox. In turn, we might increase our threshold to avoid any spam to land in the mailbox, while taking the risk of getting false positive (good mails that land in the spam folder). Trial and error is a good technique to monitor the threshold and its efficiency.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once we have our features, we need to use in our logistic function.</p>
<p>For example:</p>
$$x = \beta_{0} + \beta{1}Feat1 + \beta_{2}Feat2 $$<p></p>
<p>Where Feat1 is our value for Feature 1 and Feat2 is our value for Feature 2. For those of you familiar with <a href="https://juls-dotcom.github.io/regression_approaches.html">Linear Regression</a> this looks very familiar. Basically we are assuming that x is a linear combination of our data plus an intercept.</p>
<p>For example, take the iris dataset. Say we have a plant with a sepal width of 3.5 and a sepal length of 5.Say we already know the parameters $\beta$(s) do that $\beta_{0} = 1$, $\beta_{1} = 2$, and $\beta_{2} = 4$. This would imply:</p>
$$x = 1 + (2 * 3.5) + (4 * 5) = 28$$<p></p>
<p>Plugging this into our logistic function gives:</p>
$$\frac{1}{1 + e^{-28}} = .99$$<p></p>
<p>So we would give a 99% probability to a plant with those dimensions as being Setosa.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While we entered static values of $\beta$ here, these paremeters are the ones that the machine should learn, and what Logistic Regression will do for you.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Cost-function">Cost function<a class="anchor-link" href="#Cost-function">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While for the <code>Linear Regression</code> &amp; variants, the cost function was typically a <code>Residual Sum of Squares</code>, this becomes a bit more tricky with the <code>Logistic Regression</code>. Indeed, while the cost function of Linear Regression have a single minimum, that is not always the case for logistic functions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One typically used cost function is the following, which <strong>do have</strong> a single minimum:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
J(\theta) = -\frac{1}{N} \sum \limits _{n=1} ^{N} (y^n Ln(h_\theta * x^n)) + (1 - y^n) Ln(1 - h_0 * x^n)
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function might seem quite complex at first, but when scrutunizing it, some might already see an analogy with the Maximum Likelihood Estimation using probabilities (see my post on Introduction to Machine Learning). And indeed, there is a clear link since minimizing this cost function means that you would have to maximize the likelihood of that data belonging to a class.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In other words, one can find that when y = 1, $J(0)$ decreases monotonically towards 0 when $h_\theta$ is equal to 1. 
Similarly, when y = 0, the cost function is also equal to 0 when $h_\theta$ is equal to 0.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Practical-Demonstration">Practical Demonstration<a class="anchor-link" href="#Practical-Demonstration">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="World-of-Warcraft-dataset">World of Warcraft dataset<a class="anchor-link" href="#World-of-Warcraft-dataset">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will use Logistic regression to predict gamers that will churn. Check this <a href="https://github.com/myles-oneill/WoWAH-parser">repo</a> for the full data source, or get a small version of the data from my own repo, in the datasets folder. Check as well this nice <a href="https://www.youtube.com/watch?v=a0p8xnrQb4s">video</a> for a full explanation of the data.</p>
<p>To be honest about the code, the data pipe below was developed during a course I attended at the Netherlands Institute for Neuroscience in 2019. I modified a few bits here and there add some data features, but the general logic was defined by group during the course.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you will see, most of the functions are preparatory function.</p>
<p>One important one is the <code>add_churn_label</code> function, which is where the status of churner is defined. This is important, since it is the pattern that the algorithm will try to predict in unseen data.</p>
<p>The definition is a classic churn definition, with users having played in a certain time window, and having not logged into the game in a future time window.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that I focus on the implementation of the algorithm, so as usual in this series of post, i won't be going in data exploration and complex feature engineering. I leave the fun to you to explore that dataset, and increase the accurccy of the model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;/home/julien/website/datasets&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;wowah_data_small.csv&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span>
<span class="kn">import</span> <span class="nn">plotnine</span> <span class="k">as</span> <span class="nn">p9</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">start_pipeline</span><span class="p">(</span><span class="n">dataf</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">dataf</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">fix_columns</span><span class="p">(</span><span class="n">dataf</span><span class="p">):</span>
    <span class="n">dataf</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">dataf</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">dataf</span>

<span class="k">def</span> <span class="nf">fix_types</span><span class="p">(</span><span class="n">dataf</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">dataf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">timestamp</span><span class="o">=</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> 
                        <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">],</span> 
                                       <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%m/</span><span class="si">%d</span><span class="s2">/%y %H:%M:%S&quot;</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">add_ts_features</span><span class="p">(</span><span class="n">dataf</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">dataf</span>
           <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">hour</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span><span class="p">)</span>
           <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">day_of_week</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">dayofweek</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">add_month_played</span><span class="p">(</span><span class="n">dataf</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">dataf</span>
           <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">month_played</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">month_name</span><span class="p">()))</span>

<span class="k">def</span> <span class="nf">following_timestamp</span><span class="p">(</span><span class="n">dataf</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">dataf</span>
           <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;char&#39;</span><span class="p">,</span><span class="s1">&#39;timestamp&#39;</span><span class="p">])</span>
           <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">following_timestamp</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">()))</span>
           <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">following_char</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;char&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">()))</span>
           <span class="p">)</span>

<span class="k">def</span> <span class="nf">played_time</span><span class="p">(</span><span class="n">dataf</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">dataf</span>
           <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">played_time</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;following_timestamp&#39;</span><span class="p">])))</span>

<span class="k">def</span> <span class="nf">add_churn_label</span><span class="p">(</span><span class="n">dataf</span><span class="p">,</span> <span class="n">before_period</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;2008-01-01&quot;</span><span class="p">,</span> <span class="s2">&quot;2008-03-01&quot;</span><span class="p">),</span>
                    <span class="n">after_period</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;2008-04-01&quot;</span><span class="p">,</span> <span class="s2">&quot;2008-06-01&quot;</span><span class="p">),</span> <span class="n">min_rows</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">before_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataf</span>
                 <span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">before_period</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
                 <span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">before_period</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
 
    <span class="n">after_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataf</span>
                 <span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">after_period</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
                 <span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">after_period</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
 
    <span class="n">before_chars</span> <span class="o">=</span> <span class="p">(</span><span class="n">before_df</span>
     <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;char&quot;</span><span class="p">)</span>
     <span class="o">.</span><span class="n">count</span><span class="p">()</span>
     <span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;level&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_rows</span><span class="p">]</span>
     <span class="o">.</span><span class="n">reset_index</span><span class="p">()[</span><span class="s1">&#39;char&#39;</span><span class="p">])</span>
 
    <span class="n">after_chars</span> <span class="o">=</span> <span class="p">(</span><span class="n">after_df</span>
     <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;char&quot;</span><span class="p">)</span>
     <span class="o">.</span><span class="n">count</span><span class="p">()</span>
     <span class="o">.</span><span class="n">reset_index</span><span class="p">()[</span><span class="s1">&#39;char&#39;</span><span class="p">])</span>
 
    <span class="k">return</span> <span class="p">(</span><span class="n">before_df</span>
     <span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;char&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">before_chars</span><span class="p">)]</span>
     <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">churned</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;char&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">after_chars</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">))</span>

<span class="n">df_clean</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span>
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">start_pipeline</span><span class="p">)</span>
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">fix_columns</span><span class="p">)</span>
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">fix_types</span><span class="p">)</span>
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">add_ts_features</span><span class="p">)</span>
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">add_month_played</span><span class="p">)</span>
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">following_timestamp</span><span class="p">)</span>     
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">played_time</span><span class="p">)</span> 
 <span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">add_churn_label</span><span class="p">)</span>       
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The feature <code>char</code> defines the user in the dataframe, together with the entries for playing. Let's group by that and compute a few relevant data features to feed the model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ml_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_clean</span>
       <span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;char&#39;</span><span class="p">])</span>
       <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span>
           <span class="s2">&quot;time_played&quot;</span><span class="p">:</span> <span class="n">d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s2">&quot;churned&quot;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;churned&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span>
           <span class="s2">&quot;mean_level&quot;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
           <span class="s2">&quot;var_level&quot;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(),</span>
           <span class="s2">&quot;guild_bool&quot;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;guild&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span>
           <span class="s2">&quot;max_level&quot;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
           <span class="s2">&quot;min_level&quot;</span><span class="p">:</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
       <span class="p">}))</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">level_speed</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;max_level&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;min_level&#39;</span><span class="p">])</span> <span class="o">/</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;time_played&#39;</span><span class="p">])</span>
         <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>OK! We are ready to fit a model to predict churn. This post is about <code>Logistic Regression</code> but I will use another classification algorithm, the <code>KNeighbors Classifier</code>, as comparison.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="kn">from</span> <span class="nn">sklego.preprocessing</span> <span class="kn">import</span> <span class="n">ColumnSelector</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Pre Processing Pipeline</span>
<span class="n">panda_grabber</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;union&quot;</span><span class="p">,</span> <span class="n">FeatureUnion</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;continous&quot;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s2">&quot;select&quot;</span><span class="p">,</span> <span class="n">ColumnSelector</span><span class="p">([</span><span class="s2">&quot;max_level&quot;</span><span class="p">,</span> <span class="s2">&quot;min_level&quot;</span><span class="p">])),</span>
            <span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
        <span class="p">])),</span>
        <span class="p">(</span><span class="s2">&quot;discrete&quot;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s2">&quot;select&quot;</span><span class="p">,</span> <span class="n">ColumnSelector</span><span class="p">([</span><span class="s2">&quot;guild_bool&quot;</span><span class="p">])),</span>
            <span class="p">(</span><span class="s2">&quot;encode&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="p">]))</span>
    <span class="p">]))</span>
<span class="p">])</span>

<span class="c1"># Main Pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;grab&quot;</span><span class="p">,</span> <span class="n">panda_grabber</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;poly&quot;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
    <span class="c1">#(&quot;scale&quot;, StandardScaler()), </span>
    <span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below, I define the different models to be tested.</p>
<p>Note that I will be using LBFGS as optimization method. See <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html">here</a> for information. For gradient descent optimization, see the post on Linear Regression method.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Define polynomial</span>
<span class="n">param_poly</span> <span class="o">=</span> <span class="p">[</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="kc">None</span><span class="p">]</span>

<span class="c1"># Define models to test</span>
<span class="n">param_model</span> <span class="o">=</span> <span class="p">[</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> 
               <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> 
               <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)]</span>

<span class="c1"># Define Grid Search</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span>
                   <span class="c1">#iid=True,</span>
                   <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">param_model</span><span class="p">,</span> <span class="c1"># This overwrites the pipeline declaration of the model</span>
                               <span class="s2">&quot;poly&quot;</span><span class="p">:</span> <span class="n">param_poly</span><span class="p">},</span>
                   <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>let's fit the different models</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ml_df</span><span class="p">,</span><span class="n">ml_df</span><span class="p">[</span><span class="s1">&#39;churned&#39;</span><span class="p">]);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># look at the cross validation results and add the number of neighbors used.</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[64]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean_fit_time</th>
      <td>0.00785432</td>
      <td>0.00617559</td>
      <td>0.0076494</td>
      <td>0.00654972</td>
      <td>0.0267492</td>
      <td>0.0154052</td>
    </tr>
    <tr>
      <th>std_fit_time</th>
      <td>0.0011228</td>
      <td>0.000319191</td>
      <td>0.000846511</td>
      <td>0.000612706</td>
      <td>0.00277864</td>
      <td>0.00545565</td>
    </tr>
    <tr>
      <th>mean_score_time</th>
      <td>0.0110934</td>
      <td>0.00921001</td>
      <td>0.0115895</td>
      <td>0.0104084</td>
      <td>0.00566826</td>
      <td>0.00330086</td>
    </tr>
    <tr>
      <th>std_score_time</th>
      <td>0.00215004</td>
      <td>0.000501717</td>
      <td>0.00153521</td>
      <td>0.000850591</td>
      <td>0.000125533</td>
      <td>0.00119705</td>
    </tr>
    <tr>
      <th>param_model</th>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>
      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>
    </tr>
    <tr>
      <th>param_poly</th>
      <td>PolynomialFeatures(degree=2, include_bias=True...</td>
      <td>None</td>
      <td>PolynomialFeatures(degree=2, include_bias=True...</td>
      <td>None</td>
      <td>PolynomialFeatures(degree=2, include_bias=True...</td>
      <td>None</td>
    </tr>
    <tr>
      <th>params</th>
      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>
      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>
      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>
      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>
      <td>{'model': LogisticRegression(C=1.0, class_weig...</td>
      <td>{'model': LogisticRegression(C=1.0, class_weig...</td>
    </tr>
    <tr>
      <th>split0_test_score</th>
      <td>0.746094</td>
      <td>0.742188</td>
      <td>0.753906</td>
      <td>0.75</td>
      <td>0.746094</td>
      <td>0.746094</td>
    </tr>
    <tr>
      <th>split1_test_score</th>
      <td>0.726562</td>
      <td>0.722656</td>
      <td>0.746094</td>
      <td>0.75</td>
      <td>0.746094</td>
      <td>0.746094</td>
    </tr>
    <tr>
      <th>split2_test_score</th>
      <td>0.761719</td>
      <td>0.753906</td>
      <td>0.753906</td>
      <td>0.757812</td>
      <td>0.75</td>
      <td>0.746094</td>
    </tr>
    <tr>
      <th>split3_test_score</th>
      <td>0.765625</td>
      <td>0.195312</td>
      <td>0.773438</td>
      <td>0.773438</td>
      <td>0.765625</td>
      <td>0.761719</td>
    </tr>
    <tr>
      <th>split4_test_score</th>
      <td>0.707031</td>
      <td>0.734375</td>
      <td>0.75</td>
      <td>0.734375</td>
      <td>0.75</td>
      <td>0.75</td>
    </tr>
    <tr>
      <th>split5_test_score</th>
      <td>0.695312</td>
      <td>0.722656</td>
      <td>0.75</td>
      <td>0.75</td>
      <td>0.742188</td>
      <td>0.75</td>
    </tr>
    <tr>
      <th>split6_test_score</th>
      <td>0.710938</td>
      <td>0.703125</td>
      <td>0.746094</td>
      <td>0.753906</td>
      <td>0.742188</td>
      <td>0.746094</td>
    </tr>
    <tr>
      <th>split7_test_score</th>
      <td>0.707031</td>
      <td>0.671875</td>
      <td>0.742188</td>
      <td>0.753906</td>
      <td>0.777344</td>
      <td>0.773438</td>
    </tr>
    <tr>
      <th>split8_test_score</th>
      <td>0.617188</td>
      <td>0.574219</td>
      <td>0.714844</td>
      <td>0.707031</td>
      <td>0.714844</td>
      <td>0.804688</td>
    </tr>
    <tr>
      <th>split9_test_score</th>
      <td>0.47451</td>
      <td>0.45098</td>
      <td>0.560784</td>
      <td>0.52549</td>
      <td>0.407843</td>
      <td>0.407843</td>
    </tr>
    <tr>
      <th>mean_test_score</th>
      <td>0.691201</td>
      <td>0.627129</td>
      <td>0.729125</td>
      <td>0.725596</td>
      <td>0.714222</td>
      <td>0.723206</td>
    </tr>
    <tr>
      <th>std_test_score</th>
      <td>0.0825324</td>
      <td>0.16945</td>
      <td>0.0577515</td>
      <td>0.068688</td>
      <td>0.103272</td>
      <td>0.106598</td>
    </tr>
    <tr>
      <th>rank_test_score</th>
      <td>5</td>
      <td>6</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>split0_train_score</th>
      <td>0.836735</td>
      <td>0.835432</td>
      <td>0.772471</td>
      <td>0.773339</td>
      <td>0.761615</td>
      <td>0.759444</td>
    </tr>
    <tr>
      <th>split1_train_score</th>
      <td>0.841511</td>
      <td>0.841511</td>
      <td>0.778116</td>
      <td>0.777681</td>
      <td>0.758576</td>
      <td>0.759878</td>
    </tr>
    <tr>
      <th>split2_train_score</th>
      <td>0.847156</td>
      <td>0.828485</td>
      <td>0.776379</td>
      <td>0.774642</td>
      <td>0.761615</td>
      <td>0.75901</td>
    </tr>
    <tr>
      <th>split3_train_score</th>
      <td>0.845419</td>
      <td>0.50977</td>
      <td>0.7703</td>
      <td>0.768997</td>
      <td>0.759878</td>
      <td>0.760313</td>
    </tr>
    <tr>
      <th>split4_train_score</th>
      <td>0.838472</td>
      <td>0.815458</td>
      <td>0.774642</td>
      <td>0.775944</td>
      <td>0.75901</td>
      <td>0.758142</td>
    </tr>
    <tr>
      <th>split5_train_score</th>
      <td>0.829353</td>
      <td>0.8363</td>
      <td>0.775076</td>
      <td>0.77551</td>
      <td>0.760747</td>
      <td>0.75901</td>
    </tr>
    <tr>
      <th>split6_train_score</th>
      <td>0.846287</td>
      <td>0.837169</td>
      <td>0.775076</td>
      <td>0.771168</td>
      <td>0.759878</td>
      <td>0.758576</td>
    </tr>
    <tr>
      <th>split7_train_score</th>
      <td>0.825011</td>
      <td>0.818498</td>
      <td>0.773339</td>
      <td>0.7703</td>
      <td>0.758142</td>
      <td>0.756839</td>
    </tr>
    <tr>
      <th>split8_train_score</th>
      <td>0.827616</td>
      <td>0.818063</td>
      <td>0.771168</td>
      <td>0.770734</td>
      <td>0.750326</td>
      <td>0.751628</td>
    </tr>
    <tr>
      <th>split9_train_score</th>
      <td>0.825521</td>
      <td>0.820312</td>
      <td>0.78125</td>
      <td>0.78125</td>
      <td>0.768663</td>
      <td>0.766927</td>
    </tr>
    <tr>
      <th>mean_train_score</th>
      <td>0.836308</td>
      <td>0.7961</td>
      <td>0.774782</td>
      <td>0.773957</td>
      <td>0.759845</td>
      <td>0.758977</td>
    </tr>
    <tr>
      <th>std_train_score</th>
      <td>0.00836732</td>
      <td>0.0958596</td>
      <td>0.00310267</td>
      <td>0.00361133</td>
      <td>0.00425055</td>
      <td>0.00354195</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)[[</span><span class="s1">&#39;param_model&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_test_score&#39;</span><span class="p">,</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[65]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>param_model</th>
      <th>mean_train_score</th>
      <th>mean_test_score</th>
      <th>std_test_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>0.836308</td>
      <td>0.691201</td>
      <td>0.082532</td>
    </tr>
    <tr>
      <th>1</th>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>0.796100</td>
      <td>0.627129</td>
      <td>0.169450</td>
    </tr>
    <tr>
      <th>2</th>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>0.774782</td>
      <td>0.729125</td>
      <td>0.057752</td>
    </tr>
    <tr>
      <th>3</th>
      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>
      <td>0.773957</td>
      <td>0.725596</td>
      <td>0.068688</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>
      <td>0.759845</td>
      <td>0.714222</td>
      <td>0.103272</td>
    </tr>
    <tr>
      <th>5</th>
      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>
      <td>0.758977</td>
      <td>0.723206</td>
      <td>0.106598</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see, the <code>Logistic Regression</code> shows a nice score in the test set. It is not much better than the KNN classifier, but in my opinion, is quite intuitive to explain to non tech stakeholders and might have therefore higher explainability power.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Final-words">Final words<a class="anchor-link" href="#Final-words">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That was it for <code>Logistic Regression</code>. Hope you enjoyed it, and drop a mail if you have any comments, questions or (constructive_ criticism).</p>

</div>
</div>
</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>



        
    </div>
        <!-- /Content --> 

        <!-- Footer -->
        <div class="footer gradient-2">
            <div class="container footer-container ">
                <div class="row">
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Shortcuts</div>
                        <ul class="list-unstyled">
                            <li><a href="/archives.html">Archives</a></li>
                            <li><a href="/tags.html">Tags</a></li>
                            <li><a href="/authors.html">Authors</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Social</div>
                        <ul class="list-unstyled">
                            <li><a href="https://www.linkedin.com/in/julien-hernandez-lallement-b47347b7/" target="_blank">LinkedIn</a></li>
                            <li><a href="https://www.xing.com/profile/Julien_HernandezLallement/cv" target="_blank">Xing</a></li>
                            <li><a href="https://www.researchgate.net/profile/Julen_Hernandez_Lallement" target="_blank">ResearchGate</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Links</div>
                        <ul class="list-unstyled">
                            <li><a href="https://github.com/juls-dotcom" target="_blank">GitHub</a></li>
                            <li><a href="https://scholar.google.com/citations?user=ppDsLgIAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a></li>
                        </ul>
                    </div> 
                    <div class="col-xs-12 col-sm-3 col-md-3 col-lg-3">
                        <p class="pull-right text-right">
                            <small><em>Proudly powered by <a href="http://docs.getpelican.com/" target="_blank">pelican</a></em></small><br/>
                            <small><em>Theme and code by <a href="https://github.com/molivier" target="_blank">molivier</a></em></small><br/>
                            <small>&copy; juls-dotcom 2019</small>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!-- /Footer -->
    </body>
</html>