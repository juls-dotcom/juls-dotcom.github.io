{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- title: course: (ML Series) Logistic Regression\n",
    "- date: 2020-10-15 12:00\n",
    "- category: course\n",
    "- tags: python, machine learning\n",
    "- slug: logistic regression\n",
    "- authors: Julien Hernandez Lallement\n",
    "- summary: A discussion of Logistic Regression algorithm\n",
    "- illustration: 2020_10_logistic_regression.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, regression methods are supervised learning techniques. They use continous scaled variables (independent variables) to predict the behavior of a dependent variable. They can use different equations that will fit straight lines (linear regression), polynomial functions (detecting interaction effects) or other funcftions to predict the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, I will be focusing on logistic regressions, which are typically used as classification algorithms. The logistic regression is however not a classsification algorithm per se, but can be used as such when a probability threshold is set to differentiate between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logisti regressions can be used in different scenarios:\n",
    "* Classifying data based on continous scaled features (when the dependent variable is a categorical data, typically binary, i.e., 0 and 1)\n",
    "* Classify whether an email is a spam or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first explain why the most common use of Logistic Regression is classification. Again, to be clear, Logistic Regression is not a classification algorithm per se. It can be used for classification is a threshold is set, above and below which the vector of features will categorize the data point as belonging to one class or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the graph below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the y axis shows the classified nature of the data points (spam or not spam), and the x axis shows a feature of these data points (say, the number of spelling mistakes in the mail's object). \n",
    "\n",
    "As you can imagine, a linear fit would be quite poor in this case. If new data comes in, with `y=1`, but with a high value of x, your linear fit will show a tremendous increase in residuals, and fit the data poorly. \n",
    "\n",
    "Moreover, if the y axis does not reflect classes but probabilities of belonging to a class, you will have issues because your linear fit might predict values >1 or <0, which would be nonsense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to circumvent this problem is to use a `sigmoidal function`, such as the logistic function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "h_0(x) = \\frac{1}{1 + e^{-\\theta_o - \\theta_1x}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is shown in the figure above. Using it, a new comer data point would be classified as 1 or 0 based on the probability threshold for $h_0$. \n",
    "\n",
    "I believe that the threshold should be decided based on business and common sense. A threshold = 0.5 would be quite flexible, allowing some \"smart\" spams (if that exists) to land in the mailbox. In turn, we mighg increase our threshold to avoid any spam to land in the mailbox, while taking the rist of getting false positive (good mails that land in the spam folder). Trial and error is a good technique to monitor the threshold and its efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While for the `Linear Regression` & variants, the cost function was typically a `Residual Sum of Squares`, this becomes a bit more tricky with the `Logistic Regression`. Indeed, while the cost function of Linear Regression have a single minimum, that is not always the case for logistic functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One typically used cost function is the following, which **do have** a single minimum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "J(\\theta) = -\\frac{1}{N} \\sum \\limits _{n=1} ^{N} (y^n Ln(h_\\theta * x^n)) + (1 - y^n) Ln(1 - h_0 * x^n)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function might seem quite complex at first, but when scrutunizing it, some might already see an analogy with the Maximum Likelihood Estimation using probabilities (see my post on Introduction to Machine Learning). And indeed, there is a clear link since minimizing this cost function means that you would have to maximize the likelihood of that data belonging to a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, one can find that when y = 1, $J(0)$ decreases monotonically towards 0 when $h_\\theta$ is equal to 1. \n",
    "Similarly, when y = 0, the cost function is also equal to 0 when $h_\\theta$ is equal to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World of Warcraft dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Logistic regression to predict gamers that will churn. Check this [repo](https://github.com/myles-oneill/WoWAH-parser) for the full data source, or get a small version of the data from my own repo, in the datasets folder. Check as well this nice [video](https://www.youtube.com/watch?v=a0p8xnrQb4s) for a full explanation of the data.\n",
    "\n",
    "To be honest about the code, the data pipe below was developed during a course I attended at the Netherlands Institute for Neuroscience in 2019. I modified a few bits here and there add some data features, but the general logic was defined by group during the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, most of the functions are preparatory function.\n",
    "\n",
    "One important one is the `add_churn_label` function, which is where the status of churner is defined. This is important, since it is the pattern that the algorithm will try to predict in unseen data.\n",
    "\n",
    "The definition is a classic churn definition, with users having played in a certain time window, and having not logged into the game in a future time window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I focus on the implementation of the algorithm, so as usual in this series of post, i won't be going in data exploration and complex feature engineering. I leave the fun to you to explore that dataset, and increase the accurccy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/julien/website/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wowah_data_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline(dataf):\n",
    "    return dataf.copy()\n",
    "\n",
    "def fix_columns(dataf):\n",
    "    dataf.columns = [c.lower().replace(\" \",\"\") for c in dataf.columns]\n",
    "    return dataf\n",
    "\n",
    "def fix_types(dataf):\n",
    "    return dataf.assign(timestamp=lambda d: \n",
    "                        pd.to_datetime(d['timestamp'], \n",
    "                                       format=\"%m/%d/%y %H:%M:%S\"))\n",
    "\n",
    "def add_ts_features(dataf):\n",
    "    return (dataf\n",
    "           .assign(hour = lambda d: d['timestamp'].dt.hour)\n",
    "           .assign(day_of_week = lambda d: d['timestamp'].dt.dayofweek))\n",
    "\n",
    "def add_month_played(dataf):\n",
    "    return (dataf\n",
    "           .assign(month_played = lambda d: d['timestamp'].dt.month_name()))\n",
    "\n",
    "def following_timestamp(dataf):\n",
    "    return (dataf\n",
    "           .sort_values(by=['char','timestamp'])\n",
    "           .assign(following_timestamp = lambda d: (d['timestamp'].shift()))\n",
    "           .assign(following_char = lambda d: (d['char'].shift()))\n",
    "           )\n",
    "\n",
    "def played_time(dataf):\n",
    "    return (dataf\n",
    "           .assign(played_time = lambda d: (d['timestamp'] - d['following_timestamp'])))\n",
    "\n",
    "def add_churn_label(dataf, before_period=(\"2008-01-01\", \"2008-03-01\"),\n",
    "                    after_period=(\"2008-04-01\", \"2008-06-01\"), min_rows=10):\n",
    "    before_df = (dataf\n",
    "                 .loc[lambda d: d['timestamp'] >= pd.to_datetime(before_period[0])]\n",
    "                 .loc[lambda d: d['timestamp'] < pd.to_datetime(before_period[1])])\n",
    " \n",
    "    after_df = (dataf\n",
    "                 .loc[lambda d: d['timestamp'] >= pd.to_datetime(after_period[0])]\n",
    "                 .loc[lambda d: d['timestamp'] < pd.to_datetime(after_period[1])])\n",
    " \n",
    "    before_chars = (before_df\n",
    "     .groupby(\"char\")\n",
    "     .count()\n",
    "     .loc[lambda d: d['level'] > min_rows]\n",
    "     .reset_index()['char'])\n",
    " \n",
    "    after_chars = (after_df\n",
    "     .groupby(\"char\")\n",
    "     .count()\n",
    "     .reset_index()['char'])\n",
    " \n",
    "    return (before_df\n",
    "     .loc[lambda d: d['char'].isin(before_chars)]\n",
    "     .assign(churned = lambda d: d['char'].isin(after_chars) == False))\n",
    "\n",
    "df_clean = (df\n",
    " .pipe(start_pipeline)\n",
    " .pipe(fix_columns)\n",
    " .pipe(fix_types)\n",
    " .pipe(add_ts_features)\n",
    " .pipe(add_month_played)\n",
    " .pipe(following_timestamp)     \n",
    " .pipe(played_time) \n",
    " .pipe(add_churn_label)       \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature `char` defines the user in the dataframe, together with the entries for playing. Let's group by that and compute a few relevant data features to feed the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = (df_clean\n",
    "       .groupby(['char'])\n",
    "       .apply(lambda d: pd.Series({\n",
    "           \"time_played\": d.shape[0],\n",
    "           \"churned\": d['churned'].any(),\n",
    "           \"mean_level\": d['level'].mean(),\n",
    "           \"var_level\": d['level'].var(),\n",
    "           \"guild_bool\": d['guild'].any(),\n",
    "           \"max_level\": d['level'].max().astype(float),\n",
    "           \"min_level\": d['level'].min().astype(float)\n",
    "       }))\n",
    "        .assign(level_speed = lambda d: (d['max_level'] - d['min_level']) / d['time_played'])\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! We are ready to fit a model to predict churn. This post is about `Logistic Regression` but I will use another classification algorithm, the `KNeighbors Classifier`, as comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklego.preprocessing import ColumnSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing Pipeline\n",
    "panda_grabber = Pipeline([\n",
    "    (\"union\", FeatureUnion([\n",
    "        (\"continous\", Pipeline([\n",
    "            (\"select\", ColumnSelector([\"max_level\", \"min_level\"])),\n",
    "            (\"scale\", StandardScaler())\n",
    "        ])),\n",
    "        (\"discrete\", Pipeline([\n",
    "            (\"select\", ColumnSelector([\"guild_bool\"])),\n",
    "            (\"encode\", OneHotEncoder(sparse=False))\n",
    "        ]))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Main Pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"grab\", panda_grabber),\n",
    "    (\"poly\", PolynomialFeatures(interaction_only=True)),\n",
    "    #(\"scale\", StandardScaler()), \n",
    "    (\"model\", KNeighborsClassifier(10, weights='distance'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define polynomial\n",
    "param_poly = [PolynomialFeatures(interaction_only=True), None]\n",
    "\n",
    "# Define models to test\n",
    "param_model = [KNeighborsClassifier(1), \n",
    "               KNeighborsClassifier(10), \n",
    "               LogisticRegression(solver='lbfgs')]\n",
    "\n",
    "# Define Grid Search\n",
    "mod = GridSearchCV(pipeline,\n",
    "                   #iid=True,\n",
    "                   return_train_score=True,\n",
    "                   param_grid={\"model\": param_model, # This overwrites the pipeline declaration of the model\n",
    "                               \"poly\": param_poly},\n",
    "                   cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's fit the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(ml_df,ml_df['churned']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.00785432</td>\n",
       "      <td>0.00617559</td>\n",
       "      <td>0.0076494</td>\n",
       "      <td>0.00654972</td>\n",
       "      <td>0.0267492</td>\n",
       "      <td>0.0154052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0011228</td>\n",
       "      <td>0.000319191</td>\n",
       "      <td>0.000846511</td>\n",
       "      <td>0.000612706</td>\n",
       "      <td>0.00277864</td>\n",
       "      <td>0.00545565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0110934</td>\n",
       "      <td>0.00921001</td>\n",
       "      <td>0.0115895</td>\n",
       "      <td>0.0104084</td>\n",
       "      <td>0.00566826</td>\n",
       "      <td>0.00330086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00215004</td>\n",
       "      <td>0.000501717</td>\n",
       "      <td>0.00153521</td>\n",
       "      <td>0.000850591</td>\n",
       "      <td>0.000125533</td>\n",
       "      <td>0.00119705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_model</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_poly</th>\n",
       "      <td>PolynomialFeatures(degree=2, include_bias=True...</td>\n",
       "      <td>None</td>\n",
       "      <td>PolynomialFeatures(degree=2, include_bias=True...</td>\n",
       "      <td>None</td>\n",
       "      <td>PolynomialFeatures(degree=2, include_bias=True...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>\n",
       "      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>\n",
       "      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>\n",
       "      <td>{'model': KNeighborsClassifier(algorithm='auto...</td>\n",
       "      <td>{'model': LogisticRegression(C=1.0, class_weig...</td>\n",
       "      <td>{'model': LogisticRegression(C=1.0, class_weig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.195312</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.761719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.574219</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>0.47451</td>\n",
       "      <td>0.45098</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.52549</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.407843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.691201</td>\n",
       "      <td>0.627129</td>\n",
       "      <td>0.729125</td>\n",
       "      <td>0.725596</td>\n",
       "      <td>0.714222</td>\n",
       "      <td>0.723206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0825324</td>\n",
       "      <td>0.16945</td>\n",
       "      <td>0.0577515</td>\n",
       "      <td>0.068688</td>\n",
       "      <td>0.103272</td>\n",
       "      <td>0.106598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.835432</td>\n",
       "      <td>0.772471</td>\n",
       "      <td>0.773339</td>\n",
       "      <td>0.761615</td>\n",
       "      <td>0.759444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.841511</td>\n",
       "      <td>0.841511</td>\n",
       "      <td>0.778116</td>\n",
       "      <td>0.777681</td>\n",
       "      <td>0.758576</td>\n",
       "      <td>0.759878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.847156</td>\n",
       "      <td>0.828485</td>\n",
       "      <td>0.776379</td>\n",
       "      <td>0.774642</td>\n",
       "      <td>0.761615</td>\n",
       "      <td>0.75901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.845419</td>\n",
       "      <td>0.50977</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>0.768997</td>\n",
       "      <td>0.759878</td>\n",
       "      <td>0.760313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.838472</td>\n",
       "      <td>0.815458</td>\n",
       "      <td>0.774642</td>\n",
       "      <td>0.775944</td>\n",
       "      <td>0.75901</td>\n",
       "      <td>0.758142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>0.829353</td>\n",
       "      <td>0.8363</td>\n",
       "      <td>0.775076</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>0.760747</td>\n",
       "      <td>0.75901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>0.846287</td>\n",
       "      <td>0.837169</td>\n",
       "      <td>0.775076</td>\n",
       "      <td>0.771168</td>\n",
       "      <td>0.759878</td>\n",
       "      <td>0.758576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>0.825011</td>\n",
       "      <td>0.818498</td>\n",
       "      <td>0.773339</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>0.758142</td>\n",
       "      <td>0.756839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>0.827616</td>\n",
       "      <td>0.818063</td>\n",
       "      <td>0.771168</td>\n",
       "      <td>0.770734</td>\n",
       "      <td>0.750326</td>\n",
       "      <td>0.751628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>0.825521</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.768663</td>\n",
       "      <td>0.766927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>0.774782</td>\n",
       "      <td>0.773957</td>\n",
       "      <td>0.759845</td>\n",
       "      <td>0.758977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00836732</td>\n",
       "      <td>0.0958596</td>\n",
       "      <td>0.00310267</td>\n",
       "      <td>0.00361133</td>\n",
       "      <td>0.00425055</td>\n",
       "      <td>0.00354195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "mean_fit_time                                              0.00785432   \n",
       "std_fit_time                                                0.0011228   \n",
       "mean_score_time                                             0.0110934   \n",
       "std_score_time                                             0.00215004   \n",
       "param_model         KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "param_poly          PolynomialFeatures(degree=2, include_bias=True...   \n",
       "params              {'model': KNeighborsClassifier(algorithm='auto...   \n",
       "split0_test_score                                            0.746094   \n",
       "split1_test_score                                            0.726562   \n",
       "split2_test_score                                            0.761719   \n",
       "split3_test_score                                            0.765625   \n",
       "split4_test_score                                            0.707031   \n",
       "split5_test_score                                            0.695312   \n",
       "split6_test_score                                            0.710938   \n",
       "split7_test_score                                            0.707031   \n",
       "split8_test_score                                            0.617188   \n",
       "split9_test_score                                             0.47451   \n",
       "mean_test_score                                              0.691201   \n",
       "std_test_score                                              0.0825324   \n",
       "rank_test_score                                                     5   \n",
       "split0_train_score                                           0.836735   \n",
       "split1_train_score                                           0.841511   \n",
       "split2_train_score                                           0.847156   \n",
       "split3_train_score                                           0.845419   \n",
       "split4_train_score                                           0.838472   \n",
       "split5_train_score                                           0.829353   \n",
       "split6_train_score                                           0.846287   \n",
       "split7_train_score                                           0.825011   \n",
       "split8_train_score                                           0.827616   \n",
       "split9_train_score                                           0.825521   \n",
       "mean_train_score                                             0.836308   \n",
       "std_train_score                                            0.00836732   \n",
       "\n",
       "                                                                    1  \\\n",
       "mean_fit_time                                              0.00617559   \n",
       "std_fit_time                                              0.000319191   \n",
       "mean_score_time                                            0.00921001   \n",
       "std_score_time                                            0.000501717   \n",
       "param_model         KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "param_poly                                                       None   \n",
       "params              {'model': KNeighborsClassifier(algorithm='auto...   \n",
       "split0_test_score                                            0.742188   \n",
       "split1_test_score                                            0.722656   \n",
       "split2_test_score                                            0.753906   \n",
       "split3_test_score                                            0.195312   \n",
       "split4_test_score                                            0.734375   \n",
       "split5_test_score                                            0.722656   \n",
       "split6_test_score                                            0.703125   \n",
       "split7_test_score                                            0.671875   \n",
       "split8_test_score                                            0.574219   \n",
       "split9_test_score                                             0.45098   \n",
       "mean_test_score                                              0.627129   \n",
       "std_test_score                                                0.16945   \n",
       "rank_test_score                                                     6   \n",
       "split0_train_score                                           0.835432   \n",
       "split1_train_score                                           0.841511   \n",
       "split2_train_score                                           0.828485   \n",
       "split3_train_score                                            0.50977   \n",
       "split4_train_score                                           0.815458   \n",
       "split5_train_score                                             0.8363   \n",
       "split6_train_score                                           0.837169   \n",
       "split7_train_score                                           0.818498   \n",
       "split8_train_score                                           0.818063   \n",
       "split9_train_score                                           0.820312   \n",
       "mean_train_score                                               0.7961   \n",
       "std_train_score                                             0.0958596   \n",
       "\n",
       "                                                                    2  \\\n",
       "mean_fit_time                                               0.0076494   \n",
       "std_fit_time                                              0.000846511   \n",
       "mean_score_time                                             0.0115895   \n",
       "std_score_time                                             0.00153521   \n",
       "param_model         KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "param_poly          PolynomialFeatures(degree=2, include_bias=True...   \n",
       "params              {'model': KNeighborsClassifier(algorithm='auto...   \n",
       "split0_test_score                                            0.753906   \n",
       "split1_test_score                                            0.746094   \n",
       "split2_test_score                                            0.753906   \n",
       "split3_test_score                                            0.773438   \n",
       "split4_test_score                                                0.75   \n",
       "split5_test_score                                                0.75   \n",
       "split6_test_score                                            0.746094   \n",
       "split7_test_score                                            0.742188   \n",
       "split8_test_score                                            0.714844   \n",
       "split9_test_score                                            0.560784   \n",
       "mean_test_score                                              0.729125   \n",
       "std_test_score                                              0.0577515   \n",
       "rank_test_score                                                     1   \n",
       "split0_train_score                                           0.772471   \n",
       "split1_train_score                                           0.778116   \n",
       "split2_train_score                                           0.776379   \n",
       "split3_train_score                                             0.7703   \n",
       "split4_train_score                                           0.774642   \n",
       "split5_train_score                                           0.775076   \n",
       "split6_train_score                                           0.775076   \n",
       "split7_train_score                                           0.773339   \n",
       "split8_train_score                                           0.771168   \n",
       "split9_train_score                                            0.78125   \n",
       "mean_train_score                                             0.774782   \n",
       "std_train_score                                            0.00310267   \n",
       "\n",
       "                                                                    3  \\\n",
       "mean_fit_time                                              0.00654972   \n",
       "std_fit_time                                              0.000612706   \n",
       "mean_score_time                                             0.0104084   \n",
       "std_score_time                                            0.000850591   \n",
       "param_model         KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "param_poly                                                       None   \n",
       "params              {'model': KNeighborsClassifier(algorithm='auto...   \n",
       "split0_test_score                                                0.75   \n",
       "split1_test_score                                                0.75   \n",
       "split2_test_score                                            0.757812   \n",
       "split3_test_score                                            0.773438   \n",
       "split4_test_score                                            0.734375   \n",
       "split5_test_score                                                0.75   \n",
       "split6_test_score                                            0.753906   \n",
       "split7_test_score                                            0.753906   \n",
       "split8_test_score                                            0.707031   \n",
       "split9_test_score                                             0.52549   \n",
       "mean_test_score                                              0.725596   \n",
       "std_test_score                                               0.068688   \n",
       "rank_test_score                                                     2   \n",
       "split0_train_score                                           0.773339   \n",
       "split1_train_score                                           0.777681   \n",
       "split2_train_score                                           0.774642   \n",
       "split3_train_score                                           0.768997   \n",
       "split4_train_score                                           0.775944   \n",
       "split5_train_score                                            0.77551   \n",
       "split6_train_score                                           0.771168   \n",
       "split7_train_score                                             0.7703   \n",
       "split8_train_score                                           0.770734   \n",
       "split9_train_score                                            0.78125   \n",
       "mean_train_score                                             0.773957   \n",
       "std_train_score                                            0.00361133   \n",
       "\n",
       "                                                                    4  \\\n",
       "mean_fit_time                                               0.0267492   \n",
       "std_fit_time                                               0.00277864   \n",
       "mean_score_time                                            0.00566826   \n",
       "std_score_time                                            0.000125533   \n",
       "param_model         LogisticRegression(C=1.0, class_weight=None, d...   \n",
       "param_poly          PolynomialFeatures(degree=2, include_bias=True...   \n",
       "params              {'model': LogisticRegression(C=1.0, class_weig...   \n",
       "split0_test_score                                            0.746094   \n",
       "split1_test_score                                            0.746094   \n",
       "split2_test_score                                                0.75   \n",
       "split3_test_score                                            0.765625   \n",
       "split4_test_score                                                0.75   \n",
       "split5_test_score                                            0.742188   \n",
       "split6_test_score                                            0.742188   \n",
       "split7_test_score                                            0.777344   \n",
       "split8_test_score                                            0.714844   \n",
       "split9_test_score                                            0.407843   \n",
       "mean_test_score                                              0.714222   \n",
       "std_test_score                                               0.103272   \n",
       "rank_test_score                                                     4   \n",
       "split0_train_score                                           0.761615   \n",
       "split1_train_score                                           0.758576   \n",
       "split2_train_score                                           0.761615   \n",
       "split3_train_score                                           0.759878   \n",
       "split4_train_score                                            0.75901   \n",
       "split5_train_score                                           0.760747   \n",
       "split6_train_score                                           0.759878   \n",
       "split7_train_score                                           0.758142   \n",
       "split8_train_score                                           0.750326   \n",
       "split9_train_score                                           0.768663   \n",
       "mean_train_score                                             0.759845   \n",
       "std_train_score                                            0.00425055   \n",
       "\n",
       "                                                                    5  \n",
       "mean_fit_time                                               0.0154052  \n",
       "std_fit_time                                               0.00545565  \n",
       "mean_score_time                                            0.00330086  \n",
       "std_score_time                                             0.00119705  \n",
       "param_model         LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "param_poly                                                       None  \n",
       "params              {'model': LogisticRegression(C=1.0, class_weig...  \n",
       "split0_test_score                                            0.746094  \n",
       "split1_test_score                                            0.746094  \n",
       "split2_test_score                                            0.746094  \n",
       "split3_test_score                                            0.761719  \n",
       "split4_test_score                                                0.75  \n",
       "split5_test_score                                                0.75  \n",
       "split6_test_score                                            0.746094  \n",
       "split7_test_score                                            0.773438  \n",
       "split8_test_score                                            0.804688  \n",
       "split9_test_score                                            0.407843  \n",
       "mean_test_score                                              0.723206  \n",
       "std_test_score                                               0.106598  \n",
       "rank_test_score                                                     3  \n",
       "split0_train_score                                           0.759444  \n",
       "split1_train_score                                           0.759878  \n",
       "split2_train_score                                            0.75901  \n",
       "split3_train_score                                           0.760313  \n",
       "split4_train_score                                           0.758142  \n",
       "split5_train_score                                            0.75901  \n",
       "split6_train_score                                           0.758576  \n",
       "split7_train_score                                           0.756839  \n",
       "split8_train_score                                           0.751628  \n",
       "split9_train_score                                           0.766927  \n",
       "mean_train_score                                             0.758977  \n",
       "std_train_score                                            0.00354195  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the cross validation results and add the number of neighbors used.\n",
    "pd.DataFrame(mod.cv_results_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.691201</td>\n",
       "      <td>0.082532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.796100</td>\n",
       "      <td>0.627129</td>\n",
       "      <td>0.169450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.774782</td>\n",
       "      <td>0.729125</td>\n",
       "      <td>0.057752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.773957</td>\n",
       "      <td>0.725596</td>\n",
       "      <td>0.068688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.759845</td>\n",
       "      <td>0.714222</td>\n",
       "      <td>0.103272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.758977</td>\n",
       "      <td>0.723206</td>\n",
       "      <td>0.106598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         param_model  mean_train_score  \\\n",
       "0  KNeighborsClassifier(algorithm='auto', leaf_si...          0.836308   \n",
       "1  KNeighborsClassifier(algorithm='auto', leaf_si...          0.796100   \n",
       "2  KNeighborsClassifier(algorithm='auto', leaf_si...          0.774782   \n",
       "3  KNeighborsClassifier(algorithm='auto', leaf_si...          0.773957   \n",
       "4  LogisticRegression(C=1.0, class_weight=None, d...          0.759845   \n",
       "5  LogisticRegression(C=1.0, class_weight=None, d...          0.758977   \n",
       "\n",
       "   mean_test_score  std_test_score  \n",
       "0         0.691201        0.082532  \n",
       "1         0.627129        0.169450  \n",
       "2         0.729125        0.057752  \n",
       "3         0.725596        0.068688  \n",
       "4         0.714222        0.103272  \n",
       "5         0.723206        0.106598  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mod.cv_results_)[['param_model', 'mean_train_score', 'mean_test_score','std_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `Logistic Regression` shows a nice score in the test set. It is not much better than the KNN classifier, but in my opinion, is quite intuitive to explain to non tech stakeholders and might have therefore higher explainability power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was it for `Logistic Regression`. Hope you enjoyed it, and drop a mail if you have any comments, questions or (constructive_ criticism)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
