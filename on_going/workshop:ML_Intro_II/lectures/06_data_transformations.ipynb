{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from lib.processing_functions import convert_to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ouline\n",
    "\n",
    "Goal: Show how scikit-learn's data transformers can be used to generate suitable feature representations for model fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key topics:\n",
    "    \n",
    "- **Feature extraction**: extract feature repesentations from data like text and images\n",
    "- **Preprocessing**: preprocessing of feature vectors into a suitable format for machine learning algorithms\n",
    "- **Pipelines**: chain a set of transformers and estimators into a data pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimators versus transformers\n",
    "\n",
    "A transformer is an estimator for unsupervised learning problems:\n",
    "\n",
    "- it implements the `fit()` method for learning estimated model parameters\n",
    "- estimated model parameters are stored as attributes ending with an underscore: `est_param_`\n",
    "- learned models can be applied using the `transform()` method\n",
    "- allow simultaneous modelling and transforming through the `fit_transform()` method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature extraction\n",
    "\n",
    "Transform data, such as text or images, into numerical features that are usable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tools for feature extraction\n",
    "\n",
    "Scikit-learn has several tools for doing feature extraction:\n",
    "\n",
    "- **`DictVectorizer`**: turns lists of mappings (dict-like objects) of feature names to feature values into Numpy arrays or scipy.sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  1.],\n",
       "       [ 0.,  1.,  3.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = DictVectorizer(sparse=False)\n",
    "D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
    "X = v.fit_transform(D)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tools for feature extraction\n",
    "\n",
    "Scikit-learn has several tools for doing feature extraction:\n",
    "\n",
    "- **`FeatureHasher`**: turns sequences of symbolic feature names (strings) into scipy.sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0., -4., -1.,  0.,  0.,  0.,  0.,  0.,  2.],\n",
       "       [ 0.,  0.,  0., -2., -5.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = FeatureHasher(n_features=10)\n",
    "D = [{'dog': 1, 'cat': 2, 'elephant': 4},{'dog': 2, 'run': 5}]\n",
    "f = h.transform(D)\n",
    "f.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tools for feature extraction\n",
    "\n",
    "Scikit-learn has several tools for doing feature extraction:\n",
    "\n",
    "- **`feature_extraction.image`**: submodule that provides utilities for feature extraction from images\n",
    "- **`feature_extraction.text`**: submodule that provides utilities for feature extraction from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next we will show one of the extractors for text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bag of Words\n",
    "\n",
    "This strategy of tokenization, counting and normalization of text is called the Bag of Words or “Bag of n-grams” representation:\n",
    "\n",
    "![bow](../images/bag-of-words.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Count vectorizer\n",
    "\n",
    "Transformer that converts a collection of text documents to a sparse matrix of token counts, implementing both tokenization and occurrence counting:\n",
    "\n",
    "    text.CountVectorizer(strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Count vectorizer example\n",
    "Apply `CountVectorizer` to extract uni- and bi-grams from the corpus below and show the built vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer vocabulary:\n",
      "{'this': 18, 'is': 5, 'the': 12, 'first': 3, 'document': 2, 'this is': 19, 'is the': 6, 'the first': 13, 'first document': 4, 'second': 9, 'the second': 14, 'second second': 11, 'second document': 10, 'and': 0, 'third': 16, 'one': 8, 'and the': 1, 'the third': 15, 'third one': 17, 'is this': 7, 'this the': 20}\n",
      "\n",
      "shape of X: (4, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?']\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,2))\n",
    "X = vec.fit_transform(corpus)\n",
    "\n",
    "print(\"vectorizer vocabulary:\\n{}\".format(vec.vocabulary_))\n",
    "print(\"\\nshape of X: {}\".format(X.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now built a vectorizer that filters English stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer vocabulary: {'document': 0, 'second': 1, 'second second': 3, 'second document': 2}\n",
      "X:\n",
      "[[1 0 0 0]\n",
      " [1 2 1 1]\n",
      " [0 0 0 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "X = vec.fit_transform(corpus)\n",
    "\n",
    "print(\"vectorizer vocabulary: {}\".format(vec.vocabulary_))\n",
    "print(\"X:\\n{}\".format(X.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What happens if we transform a document containing a word that is not in the vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new: [[1 1 0 0]]\n",
      "inverse X_new: ['document' 'second']\n"
     ]
    }
   ],
   "source": [
    "X_new = vec.transform([\"A second unknown document.\"])\n",
    "\n",
    "print(\"X_new: {}\".format(X_new.toarray()))\n",
    "print(\"inverse X_new: {}\".format(vec.inverse_transform(X_new)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Raw feature vectors often need to be preprocessed before being fed to an estimator:\n",
    "\n",
    "- in order to convert features into a more suitable representation for the estimator\n",
    "- operations include scaling, centering, normalization, binarization and imputation\n",
    "\n",
    "Note that many of scikit-learn's preprocessing transformers work efficiently with sparse data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tools for preprocessing data\n",
    "\n",
    "Scikit learn provides amongst others the following tools for preprocessing:\n",
    "\n",
    "- **`StandardScaler`**: standardize the data to zero mean and unit variance\n",
    "- **`Normalizer`**: normalize each sample to have unit norm\n",
    "- **`Imputer`**: complete missing values in the data\n",
    "- **`OneHotEncoder`**: one-hot encode categorical values as binary representations\n",
    "- **`PolynomialFeatures`**: create a set of polynomial and interaction features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next we will describe some of these tools in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Standard scaler\n",
    "\n",
    "Transformer that standardizes each feature to zero mean and unit variance, a common requirement for machine learning algorithms:\n",
    "   \n",
    "```\n",
    "preprocessing.StandardScaler(with_mean=True, with_std=True, copy=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Standard scaler example\n",
    "\n",
    "Load the Boston dataset and standardize all the features using the `StandardScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>features</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.319056e-17</td>\n",
       "      <td>-3.145486e-15</td>\n",
       "      <td>-2.106352e-17</td>\n",
       "      <td>2.752300e-15</td>\n",
       "      <td>-1.150770e-14</td>\n",
       "      <td>-1.137430e-15</td>\n",
       "      <td>7.582867e-16</td>\n",
       "      <td>5.616939e-17</td>\n",
       "      <td>5.616939e-17</td>\n",
       "      <td>-1.022283e-14</td>\n",
       "      <td>8.593916e-15</td>\n",
       "      <td>-5.897786e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000990</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-1.557842e+00</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-1.465882e+00</td>\n",
       "      <td>-3.880249e+00</td>\n",
       "      <td>-2.335437e+00</td>\n",
       "      <td>-1.267069e+00</td>\n",
       "      <td>-9.828429e-01</td>\n",
       "      <td>-1.313990e+00</td>\n",
       "      <td>-2.707379e+00</td>\n",
       "      <td>-3.907193e+00</td>\n",
       "      <td>-1.531127e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.408896</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-8.676906e-01</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-9.130288e-01</td>\n",
       "      <td>-5.686303e-01</td>\n",
       "      <td>-8.374480e-01</td>\n",
       "      <td>-8.056878e-01</td>\n",
       "      <td>-6.379618e-01</td>\n",
       "      <td>-7.675760e-01</td>\n",
       "      <td>-4.880391e-01</td>\n",
       "      <td>2.050715e-01</td>\n",
       "      <td>-7.994200e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.388582</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-2.110985e-01</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-1.442174e-01</td>\n",
       "      <td>-1.084655e-01</td>\n",
       "      <td>3.173816e-01</td>\n",
       "      <td>-2.793234e-01</td>\n",
       "      <td>-5.230014e-01</td>\n",
       "      <td>-4.646726e-01</td>\n",
       "      <td>2.748590e-01</td>\n",
       "      <td>3.811865e-01</td>\n",
       "      <td>-1.812536e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.006248</td>\n",
       "      <td>4.877224e-02</td>\n",
       "      <td>1.015999e+00</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>5.986790e-01</td>\n",
       "      <td>4.827678e-01</td>\n",
       "      <td>9.067981e-01</td>\n",
       "      <td>6.623709e-01</td>\n",
       "      <td>1.661245e+00</td>\n",
       "      <td>1.530926e+00</td>\n",
       "      <td>8.065758e-01</td>\n",
       "      <td>4.336510e-01</td>\n",
       "      <td>6.030188e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.941735</td>\n",
       "      <td>3.804234e+00</td>\n",
       "      <td>2.422565e+00</td>\n",
       "      <td>3.668398e+00</td>\n",
       "      <td>2.732346e+00</td>\n",
       "      <td>3.555044e+00</td>\n",
       "      <td>1.117494e+00</td>\n",
       "      <td>3.960518e+00</td>\n",
       "      <td>1.661245e+00</td>\n",
       "      <td>1.798194e+00</td>\n",
       "      <td>1.638828e+00</td>\n",
       "      <td>4.410519e-01</td>\n",
       "      <td>3.548771e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "features        CRIM            ZN         INDUS          CHAS           NOX  \\\n",
       "count     506.000000  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean        0.000000  6.319056e-17 -3.145486e-15 -2.106352e-17  2.752300e-15   \n",
       "std         1.000990  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min        -0.417713 -4.877224e-01 -1.557842e+00 -2.725986e-01 -1.465882e+00   \n",
       "25%        -0.408896 -4.877224e-01 -8.676906e-01 -2.725986e-01 -9.130288e-01   \n",
       "50%        -0.388582 -4.877224e-01 -2.110985e-01 -2.725986e-01 -1.442174e-01   \n",
       "75%         0.006248  4.877224e-02  1.015999e+00 -2.725986e-01  5.986790e-01   \n",
       "max         9.941735  3.804234e+00  2.422565e+00  3.668398e+00  2.732346e+00   \n",
       "\n",
       "features            RM           AGE           DIS           RAD  \\\n",
       "count     5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean     -1.150770e-14 -1.137430e-15  7.582867e-16  5.616939e-17   \n",
       "std       1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min      -3.880249e+00 -2.335437e+00 -1.267069e+00 -9.828429e-01   \n",
       "25%      -5.686303e-01 -8.374480e-01 -8.056878e-01 -6.379618e-01   \n",
       "50%      -1.084655e-01  3.173816e-01 -2.793234e-01 -5.230014e-01   \n",
       "75%       4.827678e-01  9.067981e-01  6.623709e-01  1.661245e+00   \n",
       "max       3.555044e+00  1.117494e+00  3.960518e+00  1.661245e+00   \n",
       "\n",
       "features           TAX       PTRATIO             B         LSTAT  \n",
       "count     5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  \n",
       "mean      5.616939e-17 -1.022283e-14  8.593916e-15 -5.897786e-16  \n",
       "std       1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  \n",
       "min      -1.313990e+00 -2.707379e+00 -3.907193e+00 -1.531127e+00  \n",
       "25%      -7.675760e-01 -4.880391e-01  2.050715e-01 -7.994200e-01  \n",
       "50%      -4.646726e-01  2.748590e-01  3.811865e-01 -1.812536e-01  \n",
       "75%       1.530926e+00  8.065758e-01  4.336510e-01  6.030188e-01  \n",
       "max       1.798194e+00  1.638828e+00  4.410519e-01  3.548771e+00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = convert_to_pandas(datasets.load_boston())\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.transform(X), columns=X.columns)\n",
    "\n",
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Show the histograms of the original and scaled RM feature in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2, sharey=True, figsize=(16, 6))\n",
    "X.RM.hist(ax=axes[0])\n",
    "axes[0].set_title('orginal RM')\n",
    "X_scaled.RM.hist(ax=axes[1])\n",
    "axes[1].set_title('scaled RM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imputer of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer that completes missing values in the dataset:\n",
    "\n",
    "```\n",
    "preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Imputer example:\n",
    "\n",
    "Impute the missing values in the data below with the sample mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed X:\n",
      "[[ 1.   2.   3. ]\n",
      " [ 3.5  3.   4. ]\n",
      " [ 6.   7.   8. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "X = pd.DataFrame([[1, 2, 3], [None, 3, 4], [6, 7, 8]])\n",
    "\n",
    "imputer = Imputer(strategy='mean', axis=1).fit(X)\n",
    "\n",
    "X_imputed = imputer.transform(X)\n",
    "\n",
    "print(\"imputed X:\\n{}\".format(X_imputed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-hot encoder\n",
    "\n",
    "Transformer that encodes integer categorical features using a one-hot (also know as one-of-K) coding scheme:\n",
    "\n",
    "    preprocessing.OneHotEncoder(categorical_features='all', sparse=True, handle_unknown='error', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usage details:\n",
    "\n",
    "- if only specific features should be encoded, pass the indices or a mask into the `categorical_features` parameter, otherwise all features are encoded\n",
    "- the default output will be sparse unless `sparse` is `False`\n",
    "- an error will be raised when an unkown feature is presented during transform; to ignore, set `handle_unkown` to 'ignore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### One-hot encoder example\n",
    "\n",
    "One-hot encode the color column in the dataframe below using one-hot encoding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yellow</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color  radius\n",
       "0     red     1.5\n",
       "1  yellow     1.1\n",
       "2    blue     1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(\n",
    "    [['red',1.5],['yellow',1.1], ['blue', 1.]], columns=['color','radius'])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, convert the categorical values into integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  radius\n",
       "0      1     1.5\n",
       "1      2     1.1\n",
       "2      0     1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_int = X.copy()\n",
    "X_int.color = LabelEncoder().fit_transform(X.color)\n",
    "X_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, apply one-hot encoding to first feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot X:\n",
      "[[ 0.   1.   0.   1.5]\n",
      " [ 0.   0.   1.   1.1]\n",
      " [ 1.   0.   0.   1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(categorical_features=[0])\n",
    "    \n",
    "X_onehot = encoder.fit_transform(X_int)\n",
    "\n",
    "print(\"one-hot X:\\n{}\".format(X_onehot.todense()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Easier and faster Pandas alternative? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_red</th>\n",
       "      <th>color_yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius  color_blue  color_red  color_yellow\n",
       "0     1.5           0          1             0\n",
       "1     1.1           0          0             1\n",
       "2     1.0           1          0             0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines\n",
    "\n",
    "The `sklearn.pipeline` module facilitates the creation of a data pipeline; it chains multiple estimators/transformers together.\n",
    "\n",
    "Main reasons for using pipelines:\n",
    "\n",
    "- **Convenience**: only one call necessary to `fit` or `predict` a whole sequence of estimator objects\n",
    "- **Joint parameter selection**: allows grid search over parameters of all objects in the pipeline at once\n",
    "\n",
    "\n",
    "The parameters of the objects in the various steps can be accessed through the `stepname__param` attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are two functions for building pipelines:\n",
    "\n",
    "- **`pipeline.Pipeline`**: takes a list of `(key, value)` pairs, where the key is the name of a step and value the estimator object\n",
    "- **`pipeline.make_pipeline`**: is a shorthand for constructing pipelines; this function can fill out the step names automatically\n",
    "\n",
    "All estimators in a pipeline must be transformers except for the last one; the last estimator may be of any type (transformer, classifier, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pipeline example\n",
    "\n",
    "Use `Pipeline` to build an estimator that first standardizes the data and then perform Lasso regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                     (\"lasso\", Lasso())])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use `GridSearchCV` to optimize both steps while fitting on the Boston dataset and show the best estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=False)), ('lasso', Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X, y = convert_to_pandas(datasets.load_boston())\n",
    "\n",
    "params = dict(lasso__alpha=[0.01, 0.1, 1, 10],\n",
    "              scaler__with_std=[True, False],\n",
    "              scaler__with_mean=[True, False],)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid=params, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature union\n",
    "\n",
    "Feature unions combine the results of multiple transformers into a single output. In contrast to a pipeline, it operates in parallel, not series.\n",
    "\n",
    "Build a feature union transformer using:\n",
    "\n",
    "    pipeline.FeatureUnion(transformer_list, n_jobs=1, transformer_weights=None)\n",
    "\n",
    "Usage is similar to `Pipeline`, except that it also allows weighting of the different transformer ouputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature union example\n",
    "\n",
    "Create a feature union that applies both the `Binarizer` and `Normalizer` separately on the data below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import Binarizer, Normalizer\n",
    "\n",
    "X = np.arange(6).reshape(3, 2).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 2.,  3.],\n",
       "       [ 4.,  5.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]]\n",
      "X_feat:\n",
      "[[ 0.          0.          0.          1.        ]\n",
      " [ 0.          1.          0.5547002   0.83205029]\n",
      " [ 1.          1.          0.62469505  0.78086881]]\n"
     ]
    }
   ],
   "source": [
    "features = FeatureUnion(\n",
    "    [('bin',Binarizer(threshold=2)),('norm', Normalizer())])\n",
    "X_feat = features.fit_transform(X)\n",
    "\n",
    "print(\"X:\\n{}\".format(X))\n",
    "print(\"X_feat:\\n{}\".format(X_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating your own estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are situations when you'll want to create your own models and transformers:\n",
    "\n",
    "+ your problem may ask for a classifier that's not in `sklearn`\n",
    "+ you'll have a specific way of transforming features\n",
    "+ you might want to optimize the parameters of your intricate preprocessing flow.\n",
    "\n",
    "Putting your logic in objects that are similar to those of `sklearn` allows you leverage all the functionality in `sklearn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we want to create our own transformers or models, we'll have to create an estimator object.\n",
    "The estimator is one of the main concept behind `sklearn`'s API and encompasses both models and transformers:\n",
    "\n",
    "> \"An estimator learns from data; it may be a classification, regression or clustering algorithm or a transformer that extracts/filters useful features from raw data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you want to create your own estimator that complies with the `sklearn` API, inherit from the `base.BaseEstimator` and one of the following mixin classes:\n",
    "\n",
    "* `base.ClassifierMixin`\n",
    "* `base.RegressorMixin`\n",
    "* `base.ClusterMixin`\n",
    "* `base.TransformerMixin`\n",
    "\n",
    "or a more specialized base mixin classes (e.g. `sklearn.linear_model.base.LinearClassifierMixin`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The [`base.BaseEstimator`](http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) imbues your estimator with the functionality of getting and setting (hyper-)parameters. The mixin classes add basic interfaces to the `base.Estimator` required for a classifier or a model. For instance, the `base.TransformerMixin` class adds the method `fit_transform()` that chains `fit()` and `transform()` in one call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "More details on what method is required and which method should return what, see the documentation on [Rolling your own estimator](http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator). The concept of mixin classes is demonstrated in the [Python Cookbook](https://d.cxcore.net/Python/Python_Cookbook_3rd_Edition.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class HourOfDayTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        hours = [d.hour for d in X]\n",
    "        return hours\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "data = [datetime.datetime(2016, 1, 1, 1, 0), \n",
    "        datetime.datetime(2016, 1, 1, 2, 0)]\n",
    "\n",
    "transfomer = HourOfDayTransformer()\n",
    "transfomer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Notes\n",
    "\n",
    "* Multiple inheritance works from left to right.\n",
    "* Be careful with multiple inheritance. You don't want to end up with a [diamond of death](http://www.python-course.eu/images/multiple_inheritance_diamond.png) where you don't know from which class a method was inherited from.\n",
    "* When calling `__init__` from a parent class, use:\n",
    "\n",
    "```python\n",
    "# Python 2\n",
    "class Classname(OldStyleParent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        OldStyleParent.__init__(self, *args, **kwargs)\n",
    "        \n",
    "        \n",
    "# Python 3\n",
    "class Classname(NewStyleParent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review \n",
    "\n",
    "1. What does an `Imputer` do? \n",
    "2. What does a `CountVectorizer` do?\n",
    "3. If you have multiple data transformations before your ML algorithm, what is the nicest way to bundle these steps together? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises: [lab 6 - Data transformation](../labs/lab_06_data_transformation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "livereveal": {
   "start_slideshow_at": "selected",
   "transition": "convex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
